{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24915da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa798bca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ds = np.load('dataset/3_2_0_256.npz', allow_pickle=True)\n",
    "db_train, db_test = ds['pahdb']\n",
    "fp_train, fp_test = ds['fingerprint']\n",
    "spec_train, spec_test = ds['spectrum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62263be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def emd_loss(y_true, y_pred):\n",
    "#     y_true = y_true / tf.reduce_sum(y_true, axis=-1)[:, None]\n",
    "#     y_pred = y_pred / tf.reduce_sum(y_pred, axis=-1)[:, None]\n",
    "    loss = tf.math.abs(tf.math.cumsum(y_true - y_pred, axis=-1))\n",
    "    return tf.reduce_sum(loss, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b9a19f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential/dense/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential/dense/embedding_lookup_sparse/Reshape:0\", shape=(None, 2048), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential/dense/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 - 2s - loss: 10.0033 - val_loss: 6.4605\n",
      "Epoch 2/1000\n",
      "74/74 - 0s - loss: 5.9387 - val_loss: 5.8294\n",
      "Epoch 3/1000\n",
      "74/74 - 0s - loss: 5.4449 - val_loss: 5.4229\n",
      "Epoch 4/1000\n",
      "74/74 - 0s - loss: 4.8587 - val_loss: 4.8597\n",
      "Epoch 5/1000\n",
      "74/74 - 0s - loss: 4.3494 - val_loss: 4.5695\n",
      "Epoch 6/1000\n",
      "74/74 - 0s - loss: 4.1805 - val_loss: 4.5562\n",
      "Epoch 7/1000\n",
      "74/74 - 0s - loss: 4.0119 - val_loss: 4.3773\n",
      "Epoch 8/1000\n",
      "74/74 - 0s - loss: 3.7985 - val_loss: 4.4055\n",
      "Epoch 9/1000\n",
      "74/74 - 0s - loss: 3.7330 - val_loss: 4.3260\n",
      "Epoch 10/1000\n",
      "74/74 - 0s - loss: 3.6799 - val_loss: 4.3139\n",
      "Epoch 11/1000\n",
      "74/74 - 0s - loss: 3.5972 - val_loss: 4.2618\n",
      "Epoch 12/1000\n",
      "74/74 - 0s - loss: 3.4690 - val_loss: 4.2448\n",
      "Epoch 13/1000\n",
      "74/74 - 0s - loss: 3.4560 - val_loss: 4.3418\n",
      "Epoch 14/1000\n",
      "74/74 - 0s - loss: 3.2802 - val_loss: 4.2629\n",
      "Epoch 15/1000\n",
      "74/74 - 0s - loss: 3.1817 - val_loss: 4.0900\n",
      "Epoch 16/1000\n",
      "74/74 - 0s - loss: 3.1125 - val_loss: 4.1639\n",
      "Epoch 17/1000\n",
      "74/74 - 0s - loss: 3.0850 - val_loss: 4.1410\n",
      "Epoch 18/1000\n",
      "74/74 - 0s - loss: 3.0457 - val_loss: 4.1380\n",
      "Epoch 19/1000\n",
      "74/74 - 0s - loss: 2.9850 - val_loss: 4.0657\n",
      "Epoch 20/1000\n",
      "74/74 - 0s - loss: 2.9500 - val_loss: 4.1372\n",
      "Epoch 21/1000\n",
      "74/74 - 0s - loss: 2.9768 - val_loss: 4.0651\n",
      "Epoch 22/1000\n",
      "74/74 - 0s - loss: 2.8396 - val_loss: 4.1307\n",
      "Epoch 23/1000\n",
      "74/74 - 0s - loss: 2.8473 - val_loss: 4.4324\n",
      "Epoch 24/1000\n",
      "74/74 - 0s - loss: 2.9000 - val_loss: 4.1003\n",
      "Epoch 25/1000\n",
      "74/74 - 0s - loss: 2.7999 - val_loss: 4.0072\n",
      "Epoch 26/1000\n",
      "74/74 - 0s - loss: 2.7375 - val_loss: 4.0620\n",
      "Epoch 27/1000\n",
      "74/74 - 0s - loss: 2.7226 - val_loss: 4.1284\n",
      "Epoch 28/1000\n",
      "74/74 - 0s - loss: 2.7500 - val_loss: 4.0389\n",
      "Epoch 29/1000\n",
      "74/74 - 0s - loss: 2.6448 - val_loss: 3.8598\n",
      "Epoch 30/1000\n",
      "74/74 - 0s - loss: 2.6438 - val_loss: 3.9370\n",
      "Epoch 31/1000\n",
      "74/74 - 0s - loss: 2.6250 - val_loss: 4.0012\n",
      "Epoch 32/1000\n",
      "74/74 - 0s - loss: 2.5886 - val_loss: 3.9805\n",
      "Epoch 33/1000\n",
      "74/74 - 0s - loss: 2.5745 - val_loss: 3.9410\n",
      "Epoch 34/1000\n",
      "74/74 - 0s - loss: 2.4999 - val_loss: 3.8777\n",
      "Epoch 35/1000\n",
      "74/74 - 0s - loss: 2.6265 - val_loss: 3.8312\n",
      "Epoch 36/1000\n",
      "74/74 - 0s - loss: 2.5391 - val_loss: 3.8465\n",
      "Epoch 37/1000\n",
      "74/74 - 0s - loss: 2.4251 - val_loss: 3.8978\n",
      "Epoch 38/1000\n",
      "74/74 - 0s - loss: 2.4312 - val_loss: 3.9300\n",
      "Epoch 39/1000\n",
      "74/74 - 0s - loss: 2.4091 - val_loss: 3.9433\n",
      "Epoch 40/1000\n",
      "74/74 - 0s - loss: 2.3861 - val_loss: 4.0090\n",
      "Epoch 41/1000\n",
      "74/74 - 0s - loss: 2.3382 - val_loss: 3.8224\n",
      "Epoch 42/1000\n",
      "74/74 - 0s - loss: 2.3238 - val_loss: 3.7508\n",
      "Epoch 43/1000\n",
      "74/74 - 0s - loss: 2.3336 - val_loss: 3.9059\n",
      "Epoch 44/1000\n",
      "74/74 - 0s - loss: 2.2940 - val_loss: 3.9375\n",
      "Epoch 45/1000\n",
      "74/74 - 0s - loss: 2.2846 - val_loss: 3.9024\n",
      "Epoch 46/1000\n",
      "74/74 - 0s - loss: 2.2795 - val_loss: 3.8009\n",
      "Epoch 47/1000\n",
      "74/74 - 0s - loss: 2.2358 - val_loss: 3.8529\n",
      "Epoch 48/1000\n",
      "74/74 - 0s - loss: 2.2684 - val_loss: 3.7442\n",
      "Epoch 49/1000\n",
      "74/74 - 0s - loss: 2.2138 - val_loss: 3.9075\n",
      "Epoch 50/1000\n",
      "74/74 - 0s - loss: 2.3109 - val_loss: 3.9008\n",
      "Epoch 51/1000\n",
      "74/74 - 0s - loss: 2.2573 - val_loss: 3.7721\n",
      "Epoch 52/1000\n",
      "74/74 - 0s - loss: 2.2219 - val_loss: 3.7831\n",
      "Epoch 53/1000\n",
      "74/74 - 0s - loss: 2.1950 - val_loss: 3.9034\n",
      "Epoch 54/1000\n",
      "74/74 - 0s - loss: 2.2075 - val_loss: 3.7450\n",
      "Epoch 55/1000\n",
      "74/74 - 0s - loss: 2.1556 - val_loss: 3.9268\n",
      "Epoch 56/1000\n",
      "74/74 - 0s - loss: 2.1385 - val_loss: 3.7178\n",
      "Epoch 57/1000\n",
      "74/74 - 0s - loss: 2.1776 - val_loss: 4.0193\n",
      "Epoch 58/1000\n",
      "74/74 - 0s - loss: 2.2022 - val_loss: 3.7663\n",
      "Epoch 59/1000\n",
      "74/74 - 0s - loss: 2.1358 - val_loss: 3.6955\n",
      "Epoch 60/1000\n",
      "74/74 - 0s - loss: 2.0485 - val_loss: 3.7569\n",
      "Epoch 61/1000\n",
      "74/74 - 0s - loss: 2.0938 - val_loss: 3.8184\n",
      "Epoch 62/1000\n",
      "74/74 - 0s - loss: 2.0734 - val_loss: 3.7110\n",
      "Epoch 63/1000\n",
      "74/74 - 0s - loss: 2.0608 - val_loss: 3.6467\n",
      "Epoch 64/1000\n",
      "74/74 - 0s - loss: 2.0346 - val_loss: 3.6714\n",
      "Epoch 65/1000\n",
      "74/74 - 0s - loss: 2.0082 - val_loss: 3.7369\n",
      "Epoch 66/1000\n",
      "74/74 - 0s - loss: 2.0585 - val_loss: 3.7340\n",
      "Epoch 67/1000\n",
      "74/74 - 0s - loss: 2.0113 - val_loss: 3.6719\n",
      "Epoch 68/1000\n",
      "74/74 - 0s - loss: 2.0151 - val_loss: 3.6075\n",
      "Epoch 69/1000\n",
      "74/74 - 0s - loss: 1.9550 - val_loss: 3.8514\n",
      "Epoch 70/1000\n",
      "74/74 - 0s - loss: 1.9834 - val_loss: 3.6559\n",
      "Epoch 71/1000\n",
      "74/74 - 0s - loss: 1.9704 - val_loss: 3.7112\n",
      "Epoch 72/1000\n",
      "74/74 - 0s - loss: 1.9622 - val_loss: 3.5781\n",
      "Epoch 73/1000\n",
      "74/74 - 0s - loss: 1.9155 - val_loss: 3.7046\n",
      "Epoch 74/1000\n",
      "74/74 - 0s - loss: 1.9452 - val_loss: 3.7665\n",
      "Epoch 75/1000\n",
      "74/74 - 0s - loss: 1.9973 - val_loss: 3.8059\n",
      "Epoch 76/1000\n",
      "74/74 - 0s - loss: 1.9607 - val_loss: 3.7487\n",
      "Epoch 77/1000\n",
      "74/74 - 0s - loss: 1.9455 - val_loss: 3.5955\n",
      "Epoch 78/1000\n",
      "74/74 - 0s - loss: 1.9104 - val_loss: 3.5516\n",
      "Epoch 79/1000\n",
      "74/74 - 0s - loss: 1.8788 - val_loss: 3.6754\n",
      "Epoch 80/1000\n",
      "74/74 - 0s - loss: 1.8466 - val_loss: 3.7438\n",
      "Epoch 81/1000\n",
      "74/74 - 0s - loss: 1.9056 - val_loss: 3.7222\n",
      "Epoch 82/1000\n",
      "74/74 - 0s - loss: 1.8532 - val_loss: 3.6782\n",
      "Epoch 83/1000\n",
      "74/74 - 0s - loss: 1.8682 - val_loss: 3.7846\n",
      "Epoch 84/1000\n",
      "74/74 - 0s - loss: 1.9171 - val_loss: 3.8401\n",
      "Epoch 85/1000\n",
      "74/74 - 0s - loss: 1.8817 - val_loss: 3.7676\n",
      "Epoch 86/1000\n",
      "74/74 - 0s - loss: 1.8381 - val_loss: 3.6319\n",
      "Epoch 87/1000\n",
      "74/74 - 0s - loss: 1.8750 - val_loss: 3.6068\n",
      "Epoch 88/1000\n",
      "74/74 - 0s - loss: 1.8283 - val_loss: 3.5881\n",
      "Epoch 89/1000\n",
      "74/74 - 0s - loss: 1.8273 - val_loss: 3.6286\n",
      "Epoch 90/1000\n",
      "74/74 - 0s - loss: 1.8508 - val_loss: 3.6768\n",
      "Epoch 91/1000\n",
      "74/74 - 0s - loss: 1.8890 - val_loss: 3.5915\n",
      "Epoch 92/1000\n",
      "74/74 - 0s - loss: 1.8228 - val_loss: 3.6709\n",
      "Epoch 93/1000\n",
      "74/74 - 0s - loss: 1.8143 - val_loss: 3.5456\n",
      "Epoch 94/1000\n",
      "74/74 - 0s - loss: 1.8215 - val_loss: 3.5755\n",
      "Epoch 95/1000\n",
      "74/74 - 0s - loss: 1.8366 - val_loss: 3.6323\n",
      "Epoch 96/1000\n",
      "74/74 - 0s - loss: 1.7989 - val_loss: 3.7525\n",
      "Epoch 97/1000\n",
      "74/74 - 0s - loss: 1.8402 - val_loss: 3.5912\n",
      "Epoch 98/1000\n",
      "74/74 - 0s - loss: 1.7828 - val_loss: 3.6577\n",
      "Epoch 99/1000\n",
      "74/74 - 0s - loss: 1.7681 - val_loss: 3.6015\n",
      "Epoch 100/1000\n",
      "74/74 - 0s - loss: 1.7622 - val_loss: 3.6456\n",
      "Epoch 101/1000\n",
      "74/74 - 0s - loss: 1.7861 - val_loss: 3.5088\n",
      "Epoch 102/1000\n",
      "74/74 - 0s - loss: 1.8146 - val_loss: 3.6437\n",
      "Epoch 103/1000\n",
      "74/74 - 0s - loss: 1.8001 - val_loss: 3.5441\n",
      "Epoch 104/1000\n",
      "74/74 - 0s - loss: 1.8263 - val_loss: 3.6739\n",
      "Epoch 105/1000\n",
      "74/74 - 0s - loss: 1.8160 - val_loss: 3.5964\n",
      "Epoch 106/1000\n",
      "74/74 - 0s - loss: 1.7527 - val_loss: 3.5886\n",
      "Epoch 107/1000\n",
      "74/74 - 0s - loss: 1.7657 - val_loss: 3.5879\n",
      "Epoch 108/1000\n",
      "74/74 - 0s - loss: 1.7899 - val_loss: 3.6252\n",
      "Epoch 109/1000\n",
      "74/74 - 0s - loss: 1.7448 - val_loss: 3.5854\n",
      "Epoch 110/1000\n",
      "74/74 - 0s - loss: 1.7120 - val_loss: 3.6673\n",
      "Epoch 111/1000\n",
      "74/74 - 0s - loss: 1.7476 - val_loss: 3.6169\n",
      "Epoch 112/1000\n",
      "74/74 - 0s - loss: 1.7402 - val_loss: 3.5866\n",
      "Epoch 113/1000\n",
      "74/74 - 0s - loss: 1.7066 - val_loss: 3.5739\n",
      "Epoch 114/1000\n",
      "74/74 - 0s - loss: 1.7501 - val_loss: 3.5802\n",
      "Epoch 115/1000\n",
      "74/74 - 0s - loss: 1.6874 - val_loss: 3.4928\n",
      "Epoch 116/1000\n",
      "74/74 - 0s - loss: 1.7387 - val_loss: 3.5765\n",
      "Epoch 117/1000\n",
      "74/74 - 0s - loss: 1.7443 - val_loss: 3.8211\n",
      "Epoch 118/1000\n",
      "74/74 - 0s - loss: 1.8063 - val_loss: 3.5731\n",
      "Epoch 119/1000\n",
      "74/74 - 0s - loss: 1.7277 - val_loss: 3.5414\n",
      "Epoch 120/1000\n",
      "74/74 - 0s - loss: 1.6610 - val_loss: 3.5300\n",
      "Epoch 121/1000\n",
      "74/74 - 0s - loss: 1.6605 - val_loss: 3.5869\n",
      "Epoch 122/1000\n",
      "74/74 - 0s - loss: 1.6816 - val_loss: 3.7153\n",
      "Epoch 123/1000\n",
      "74/74 - 0s - loss: 1.6875 - val_loss: 3.6138\n",
      "Epoch 124/1000\n",
      "74/74 - 0s - loss: 1.6897 - val_loss: 3.5942\n",
      "Epoch 125/1000\n",
      "74/74 - 0s - loss: 1.6965 - val_loss: 3.5419\n",
      "Epoch 126/1000\n",
      "74/74 - 0s - loss: 1.6822 - val_loss: 3.5406\n",
      "Epoch 127/1000\n",
      "74/74 - 0s - loss: 1.6688 - val_loss: 3.5724\n",
      "Epoch 128/1000\n",
      "74/74 - 0s - loss: 1.7190 - val_loss: 3.5340\n",
      "Epoch 129/1000\n",
      "74/74 - 0s - loss: 1.6578 - val_loss: 3.5611\n",
      "Epoch 130/1000\n",
      "74/74 - 0s - loss: 1.6815 - val_loss: 3.5736\n",
      "Epoch 131/1000\n",
      "74/74 - 0s - loss: 1.6537 - val_loss: 3.5035\n",
      "Epoch 132/1000\n",
      "74/74 - 0s - loss: 1.6344 - val_loss: 3.6009\n",
      "Epoch 133/1000\n",
      "74/74 - 0s - loss: 1.6547 - val_loss: 3.5466\n",
      "Epoch 134/1000\n",
      "74/74 - 0s - loss: 1.6975 - val_loss: 3.5105\n",
      "Epoch 135/1000\n",
      "74/74 - 0s - loss: 1.6728 - val_loss: 3.5656\n",
      "Epoch 136/1000\n",
      "74/74 - 0s - loss: 1.6395 - val_loss: 3.5393\n",
      "Epoch 137/1000\n",
      "74/74 - 0s - loss: 1.6657 - val_loss: 3.5736\n",
      "Epoch 138/1000\n",
      "74/74 - 0s - loss: 1.6099 - val_loss: 3.5958\n",
      "Epoch 139/1000\n",
      "74/74 - 0s - loss: 1.6598 - val_loss: 3.5787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 140/1000\n",
      "74/74 - 0s - loss: 1.6409 - val_loss: 3.5667\n",
      "Epoch 141/1000\n",
      "74/74 - 0s - loss: 1.6421 - val_loss: 3.5469\n",
      "Epoch 142/1000\n",
      "74/74 - 0s - loss: 1.6890 - val_loss: 3.5439\n",
      "Epoch 143/1000\n",
      "74/74 - 0s - loss: 1.6655 - val_loss: 3.7127\n",
      "Epoch 144/1000\n",
      "74/74 - 0s - loss: 1.6824 - val_loss: 3.4674\n",
      "Epoch 145/1000\n",
      "74/74 - 0s - loss: 1.6314 - val_loss: 3.4978\n",
      "Epoch 146/1000\n",
      "74/74 - 0s - loss: 1.6038 - val_loss: 3.4587\n",
      "Epoch 147/1000\n",
      "74/74 - 0s - loss: 1.6530 - val_loss: 3.4859\n",
      "Epoch 148/1000\n",
      "74/74 - 0s - loss: 1.6031 - val_loss: 3.5391\n",
      "Epoch 149/1000\n",
      "74/74 - 0s - loss: 1.6711 - val_loss: 3.4708\n",
      "Epoch 150/1000\n",
      "74/74 - 0s - loss: 1.5885 - val_loss: 3.5144\n",
      "Epoch 151/1000\n",
      "74/74 - 0s - loss: 1.5860 - val_loss: 3.5137\n",
      "Epoch 152/1000\n",
      "74/74 - 0s - loss: 1.6175 - val_loss: 3.5158\n",
      "Epoch 153/1000\n",
      "74/74 - 0s - loss: 1.5897 - val_loss: 3.4471\n",
      "Epoch 154/1000\n",
      "74/74 - 0s - loss: 1.5835 - val_loss: 3.4919\n",
      "Epoch 155/1000\n",
      "74/74 - 0s - loss: 1.5999 - val_loss: 3.4257\n",
      "Epoch 156/1000\n",
      "74/74 - 0s - loss: 1.6218 - val_loss: 3.5117\n",
      "Epoch 157/1000\n",
      "74/74 - 0s - loss: 1.5907 - val_loss: 3.5386\n",
      "Epoch 158/1000\n",
      "74/74 - 0s - loss: 1.5959 - val_loss: 3.4980\n",
      "Epoch 159/1000\n",
      "74/74 - 0s - loss: 1.6076 - val_loss: 3.4563\n",
      "Epoch 160/1000\n",
      "74/74 - 0s - loss: 1.5796 - val_loss: 3.5532\n",
      "Epoch 161/1000\n",
      "74/74 - 0s - loss: 1.5886 - val_loss: 3.4896\n",
      "Epoch 162/1000\n",
      "74/74 - 0s - loss: 1.5795 - val_loss: 3.5149\n",
      "Epoch 163/1000\n",
      "74/74 - 0s - loss: 1.5647 - val_loss: 3.4755\n",
      "Epoch 164/1000\n",
      "74/74 - 0s - loss: 1.5451 - val_loss: 3.4585\n",
      "Epoch 165/1000\n",
      "74/74 - 0s - loss: 1.5625 - val_loss: 3.4641\n",
      "Epoch 166/1000\n",
      "74/74 - 0s - loss: 1.5848 - val_loss: 3.5102\n",
      "Epoch 167/1000\n",
      "74/74 - 0s - loss: 1.5806 - val_loss: 3.4891\n",
      "Epoch 168/1000\n",
      "74/74 - 0s - loss: 1.5588 - val_loss: 3.5494\n",
      "Epoch 169/1000\n",
      "74/74 - 0s - loss: 1.5605 - val_loss: 3.4796\n",
      "Epoch 170/1000\n",
      "74/74 - 0s - loss: 1.5744 - val_loss: 3.4805\n",
      "Epoch 171/1000\n",
      "74/74 - 0s - loss: 1.5533 - val_loss: 3.4249\n",
      "Epoch 172/1000\n",
      "74/74 - 0s - loss: 1.5462 - val_loss: 3.4790\n",
      "Epoch 173/1000\n",
      "74/74 - 0s - loss: 1.5503 - val_loss: 3.4694\n",
      "Epoch 174/1000\n",
      "74/74 - 0s - loss: 1.5316 - val_loss: 3.4628\n",
      "Epoch 175/1000\n",
      "74/74 - 0s - loss: 1.5394 - val_loss: 3.4411\n",
      "Epoch 176/1000\n",
      "74/74 - 0s - loss: 1.5348 - val_loss: 3.4222\n",
      "Epoch 177/1000\n",
      "74/74 - 0s - loss: 1.5204 - val_loss: 3.4485\n",
      "Epoch 178/1000\n",
      "74/74 - 0s - loss: 1.5581 - val_loss: 3.6710\n",
      "Epoch 179/1000\n",
      "74/74 - 0s - loss: 1.5638 - val_loss: 3.4588\n",
      "Epoch 180/1000\n",
      "74/74 - 0s - loss: 1.5571 - val_loss: 3.5048\n",
      "Epoch 181/1000\n",
      "74/74 - 0s - loss: 1.5436 - val_loss: 3.4422\n",
      "Epoch 182/1000\n",
      "74/74 - 0s - loss: 1.5423 - val_loss: 3.4997\n",
      "Epoch 183/1000\n",
      "74/74 - 0s - loss: 1.5486 - val_loss: 3.4562\n",
      "Epoch 184/1000\n",
      "74/74 - 0s - loss: 1.5199 - val_loss: 3.4619\n",
      "Epoch 185/1000\n",
      "74/74 - 0s - loss: 1.5496 - val_loss: 3.4278\n",
      "Epoch 186/1000\n",
      "74/74 - 0s - loss: 1.5297 - val_loss: 3.4444\n",
      "Epoch 187/1000\n",
      "74/74 - 0s - loss: 1.5263 - val_loss: 3.4340\n",
      "Epoch 188/1000\n",
      "74/74 - 0s - loss: 1.4957 - val_loss: 3.5023\n",
      "Epoch 189/1000\n",
      "74/74 - 0s - loss: 1.5347 - val_loss: 3.4225\n",
      "Epoch 190/1000\n",
      "74/74 - 0s - loss: 1.4882 - val_loss: 3.4223\n",
      "Epoch 191/1000\n",
      "74/74 - 0s - loss: 1.5068 - val_loss: 3.4296\n",
      "Epoch 192/1000\n",
      "74/74 - 0s - loss: 1.4920 - val_loss: 3.4149\n",
      "Epoch 193/1000\n",
      "74/74 - 0s - loss: 1.4930 - val_loss: 3.4653\n",
      "Epoch 194/1000\n",
      "74/74 - 0s - loss: 1.5811 - val_loss: 3.4743\n",
      "Epoch 195/1000\n",
      "74/74 - 0s - loss: 1.5232 - val_loss: 3.4556\n",
      "Epoch 196/1000\n",
      "74/74 - 0s - loss: 1.5016 - val_loss: 3.4557\n",
      "Epoch 197/1000\n",
      "74/74 - 0s - loss: 1.5074 - val_loss: 3.5156\n",
      "Epoch 198/1000\n",
      "74/74 - 0s - loss: 1.5114 - val_loss: 3.4622\n",
      "Epoch 199/1000\n",
      "74/74 - 0s - loss: 1.5751 - val_loss: 3.3734\n",
      "Epoch 200/1000\n",
      "74/74 - 0s - loss: 1.5658 - val_loss: 3.3691\n",
      "\n",
      "Epoch 00200: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 201/1000\n",
      "74/74 - 0s - loss: 1.4373 - val_loss: 3.3463\n",
      "Epoch 202/1000\n",
      "74/74 - 0s - loss: 1.3613 - val_loss: 3.3790\n",
      "Epoch 203/1000\n",
      "74/74 - 0s - loss: 1.3549 - val_loss: 3.3977\n",
      "Epoch 204/1000\n",
      "74/74 - 0s - loss: 1.3556 - val_loss: 3.3944\n",
      "Epoch 205/1000\n",
      "74/74 - 0s - loss: 1.3366 - val_loss: 3.3801\n",
      "Epoch 206/1000\n",
      "74/74 - 0s - loss: 1.3527 - val_loss: 3.3818\n",
      "Epoch 207/1000\n",
      "74/74 - 0s - loss: 1.3616 - val_loss: 3.3895\n",
      "Epoch 208/1000\n",
      "74/74 - 0s - loss: 1.3417 - val_loss: 3.3652\n",
      "Epoch 209/1000\n",
      "74/74 - 0s - loss: 1.3635 - val_loss: 3.4015\n",
      "Epoch 210/1000\n",
      "74/74 - 0s - loss: 1.3542 - val_loss: 3.3881\n",
      "Epoch 211/1000\n",
      "74/74 - 0s - loss: 1.3610 - val_loss: 3.3919\n",
      "Epoch 212/1000\n",
      "74/74 - 0s - loss: 1.3493 - val_loss: 3.3697\n",
      "Epoch 213/1000\n",
      "74/74 - 0s - loss: 1.3496 - val_loss: 3.3862\n",
      "Epoch 214/1000\n",
      "74/74 - 0s - loss: 1.3332 - val_loss: 3.3605\n",
      "Epoch 215/1000\n",
      "74/74 - 0s - loss: 1.3471 - val_loss: 3.3735\n",
      "Epoch 216/1000\n",
      "74/74 - 0s - loss: 1.3360 - val_loss: 3.3771\n",
      "Epoch 217/1000\n",
      "74/74 - 0s - loss: 1.3466 - val_loss: 3.3778\n",
      "Epoch 218/1000\n",
      "74/74 - 0s - loss: 1.3427 - val_loss: 3.3915\n",
      "Epoch 219/1000\n",
      "74/74 - 0s - loss: 1.3251 - val_loss: 3.3810\n",
      "Epoch 220/1000\n",
      "74/74 - 0s - loss: 1.3281 - val_loss: 3.3901\n",
      "Epoch 221/1000\n",
      "74/74 - 0s - loss: 1.3437 - val_loss: 3.3701\n",
      "Epoch 222/1000\n",
      "74/74 - 0s - loss: 1.3403 - val_loss: 3.3322\n",
      "Epoch 223/1000\n",
      "74/74 - 0s - loss: 1.3518 - val_loss: 3.3690\n",
      "Epoch 224/1000\n",
      "74/74 - 0s - loss: 1.3418 - val_loss: 3.3597\n",
      "Epoch 225/1000\n",
      "74/74 - 0s - loss: 1.3376 - val_loss: 3.3871\n",
      "Epoch 226/1000\n",
      "74/74 - 0s - loss: 1.3577 - val_loss: 3.3390\n",
      "Epoch 227/1000\n",
      "74/74 - 0s - loss: 1.3222 - val_loss: 3.3587\n",
      "Epoch 228/1000\n",
      "74/74 - 0s - loss: 1.3352 - val_loss: 3.3709\n",
      "Epoch 229/1000\n",
      "74/74 - 0s - loss: 1.3374 - val_loss: 3.3577\n",
      "Epoch 230/1000\n",
      "74/74 - 0s - loss: 1.3358 - val_loss: 3.3445\n",
      "Epoch 231/1000\n",
      "74/74 - 0s - loss: 1.3281 - val_loss: 3.3565\n",
      "Epoch 232/1000\n",
      "74/74 - 0s - loss: 1.3301 - val_loss: 3.3585\n",
      "Epoch 233/1000\n",
      "74/74 - 0s - loss: 1.3328 - val_loss: 3.3452\n",
      "Epoch 234/1000\n",
      "74/74 - 0s - loss: 1.3308 - val_loss: 3.3530\n",
      "Epoch 235/1000\n",
      "74/74 - 0s - loss: 1.3384 - val_loss: 3.3936\n",
      "Epoch 236/1000\n",
      "74/74 - 0s - loss: 1.3349 - val_loss: 3.3266\n",
      "Epoch 237/1000\n",
      "74/74 - 0s - loss: 1.3076 - val_loss: 3.3796\n",
      "Epoch 238/1000\n",
      "74/74 - 0s - loss: 1.3191 - val_loss: 3.3166\n",
      "Epoch 239/1000\n",
      "74/74 - 0s - loss: 1.3043 - val_loss: 3.3569\n",
      "Epoch 240/1000\n",
      "74/74 - 0s - loss: 1.3147 - val_loss: 3.3293\n",
      "Epoch 241/1000\n",
      "74/74 - 0s - loss: 1.3117 - val_loss: 3.3450\n",
      "Epoch 242/1000\n",
      "74/74 - 0s - loss: 1.3233 - val_loss: 3.3652\n",
      "Epoch 243/1000\n",
      "74/74 - 0s - loss: 1.3110 - val_loss: 3.3768\n",
      "Epoch 244/1000\n",
      "74/74 - 0s - loss: 1.3386 - val_loss: 3.3618\n",
      "Epoch 245/1000\n",
      "74/74 - 0s - loss: 1.3226 - val_loss: 3.3261\n",
      "Epoch 246/1000\n",
      "74/74 - 0s - loss: 1.3369 - val_loss: 3.3412\n",
      "Epoch 247/1000\n",
      "74/74 - 0s - loss: 1.3380 - val_loss: 3.3540\n",
      "Epoch 248/1000\n",
      "74/74 - 0s - loss: 1.3251 - val_loss: 3.3815\n",
      "Epoch 249/1000\n",
      "74/74 - 0s - loss: 1.3188 - val_loss: 3.3934\n",
      "\n",
      "Epoch 00249: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 250/1000\n",
      "74/74 - 0s - loss: 1.2784 - val_loss: 3.3432\n",
      "Epoch 251/1000\n",
      "74/74 - 0s - loss: 1.2459 - val_loss: 3.3204\n",
      "Epoch 252/1000\n",
      "74/74 - 0s - loss: 1.2330 - val_loss: 3.3186\n",
      "Epoch 253/1000\n",
      "74/74 - 0s - loss: 1.2367 - val_loss: 3.3210\n",
      "Epoch 254/1000\n",
      "74/74 - 0s - loss: 1.2288 - val_loss: 3.3116\n",
      "Epoch 255/1000\n",
      "74/74 - 0s - loss: 1.2299 - val_loss: 3.3215\n",
      "Epoch 256/1000\n",
      "74/74 - 0s - loss: 1.2373 - val_loss: 3.3239\n",
      "Epoch 257/1000\n",
      "74/74 - 0s - loss: 1.2320 - val_loss: 3.3258\n",
      "Epoch 258/1000\n",
      "74/74 - 0s - loss: 1.2334 - val_loss: 3.3501\n",
      "Epoch 259/1000\n",
      "74/74 - 0s - loss: 1.2423 - val_loss: 3.3308\n",
      "Epoch 260/1000\n",
      "74/74 - 0s - loss: 1.2313 - val_loss: 3.3158\n",
      "Epoch 261/1000\n",
      "74/74 - 0s - loss: 1.2263 - val_loss: 3.3245\n",
      "Epoch 262/1000\n",
      "74/74 - 0s - loss: 1.2354 - val_loss: 3.3220\n",
      "Epoch 263/1000\n",
      "74/74 - 0s - loss: 1.2311 - val_loss: 3.3132\n",
      "Epoch 264/1000\n",
      "74/74 - 0s - loss: 1.2319 - val_loss: 3.3314\n",
      "Epoch 265/1000\n",
      "74/74 - 0s - loss: 1.2302 - val_loss: 3.3450\n",
      "Epoch 266/1000\n",
      "74/74 - 0s - loss: 1.2558 - val_loss: 3.3346\n",
      "Epoch 267/1000\n",
      "74/74 - 0s - loss: 1.2331 - val_loss: 3.3365\n",
      "Epoch 268/1000\n",
      "74/74 - 0s - loss: 1.2243 - val_loss: 3.3203\n",
      "Epoch 269/1000\n",
      "74/74 - 0s - loss: 1.2268 - val_loss: 3.3330\n",
      "Epoch 270/1000\n",
      "74/74 - 0s - loss: 1.2218 - val_loss: 3.3456\n",
      "Epoch 271/1000\n",
      "74/74 - 0s - loss: 1.2370 - val_loss: 3.3275\n",
      "Epoch 272/1000\n",
      "74/74 - 0s - loss: 1.2231 - val_loss: 3.3218\n",
      "Epoch 273/1000\n",
      "74/74 - 0s - loss: 1.2214 - val_loss: 3.3272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 274/1000\n",
      "74/74 - 0s - loss: 1.2196 - val_loss: 3.3205\n",
      "Epoch 275/1000\n",
      "74/74 - 0s - loss: 1.2239 - val_loss: 3.3195\n",
      "Epoch 276/1000\n",
      "74/74 - 0s - loss: 1.2202 - val_loss: 3.3423\n",
      "Epoch 277/1000\n",
      "74/74 - 0s - loss: 1.2250 - val_loss: 3.3285\n",
      "Epoch 278/1000\n",
      "74/74 - 0s - loss: 1.2317 - val_loss: 3.3186\n",
      "Epoch 279/1000\n",
      "74/74 - 0s - loss: 1.2199 - val_loss: 3.3143\n",
      "Epoch 280/1000\n",
      "74/74 - 0s - loss: 1.2187 - val_loss: 3.3134\n",
      "Epoch 281/1000\n",
      "74/74 - 0s - loss: 1.2134 - val_loss: 3.3182\n",
      "Epoch 282/1000\n",
      "74/74 - 0s - loss: 1.2137 - val_loss: 3.3288\n",
      "Epoch 283/1000\n",
      "74/74 - 0s - loss: 1.2188 - val_loss: 3.3179\n",
      "Epoch 284/1000\n",
      "74/74 - 0s - loss: 1.2146 - val_loss: 3.3200\n",
      "Epoch 285/1000\n",
      "74/74 - 0s - loss: 1.2265 - val_loss: 3.3335\n",
      "Epoch 286/1000\n",
      "74/74 - 0s - loss: 1.2202 - val_loss: 3.3021\n",
      "Epoch 287/1000\n",
      "74/74 - 0s - loss: 1.2166 - val_loss: 3.3175\n",
      "Epoch 288/1000\n",
      "74/74 - 0s - loss: 1.2256 - val_loss: 3.3153\n",
      "Epoch 289/1000\n",
      "74/74 - 0s - loss: 1.2191 - val_loss: 3.3351\n",
      "Epoch 290/1000\n",
      "74/74 - 0s - loss: 1.2262 - val_loss: 3.3046\n",
      "Epoch 291/1000\n",
      "74/74 - 0s - loss: 1.2099 - val_loss: 3.3285\n",
      "Epoch 292/1000\n",
      "74/74 - 0s - loss: 1.2091 - val_loss: 3.3234\n",
      "Epoch 293/1000\n",
      "74/74 - 0s - loss: 1.2148 - val_loss: 3.3225\n",
      "Epoch 294/1000\n",
      "74/74 - 0s - loss: 1.2123 - val_loss: 3.3199\n",
      "Epoch 295/1000\n",
      "74/74 - 0s - loss: 1.2112 - val_loss: 3.3260\n",
      "Epoch 296/1000\n",
      "74/74 - 0s - loss: 1.2108 - val_loss: 3.3071\n",
      "Epoch 297/1000\n",
      "74/74 - 0s - loss: 1.2078 - val_loss: 3.3217\n",
      "Epoch 298/1000\n",
      "74/74 - 0s - loss: 1.2065 - val_loss: 3.3096\n",
      "Epoch 299/1000\n",
      "74/74 - 0s - loss: 1.2064 - val_loss: 3.3124\n",
      "Epoch 300/1000\n",
      "74/74 - 0s - loss: 1.2020 - val_loss: 3.3212\n",
      "Epoch 301/1000\n",
      "74/74 - 0s - loss: 1.1987 - val_loss: 3.3126\n",
      "Epoch 302/1000\n",
      "74/74 - 0s - loss: 1.2028 - val_loss: 3.3206\n",
      "Epoch 303/1000\n",
      "74/74 - 0s - loss: 1.2070 - val_loss: 3.3129\n",
      "Epoch 304/1000\n",
      "74/74 - 0s - loss: 1.2085 - val_loss: 3.3125\n",
      "Epoch 305/1000\n",
      "74/74 - 0s - loss: 1.2090 - val_loss: 3.3167\n",
      "Epoch 306/1000\n",
      "74/74 - 0s - loss: 1.2075 - val_loss: 3.3196\n",
      "Epoch 307/1000\n",
      "74/74 - 0s - loss: 1.2030 - val_loss: 3.3041\n",
      "Epoch 308/1000\n",
      "74/74 - 0s - loss: 1.2052 - val_loss: 3.3311\n",
      "Epoch 309/1000\n",
      "74/74 - 0s - loss: 1.2069 - val_loss: 3.3046\n",
      "Epoch 310/1000\n",
      "74/74 - 0s - loss: 1.2055 - val_loss: 3.3165\n",
      "Epoch 311/1000\n",
      "74/74 - 0s - loss: 1.2009 - val_loss: 3.3058\n",
      "\n",
      "Epoch 00311: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 312/1000\n",
      "74/74 - 0s - loss: 1.1805 - val_loss: 3.3014\n",
      "Epoch 313/1000\n",
      "74/74 - 0s - loss: 1.1657 - val_loss: 3.2998\n",
      "Epoch 314/1000\n",
      "74/74 - 0s - loss: 1.1660 - val_loss: 3.3013\n",
      "Epoch 315/1000\n",
      "74/74 - 0s - loss: 1.1605 - val_loss: 3.3054\n",
      "Epoch 316/1000\n",
      "74/74 - 0s - loss: 1.1643 - val_loss: 3.3013\n",
      "Epoch 317/1000\n",
      "74/74 - 0s - loss: 1.1635 - val_loss: 3.2967\n",
      "Epoch 318/1000\n",
      "74/74 - 0s - loss: 1.1579 - val_loss: 3.2966\n",
      "Epoch 319/1000\n",
      "74/74 - 0s - loss: 1.1633 - val_loss: 3.2944\n",
      "Epoch 320/1000\n",
      "74/74 - 0s - loss: 1.1604 - val_loss: 3.3017\n",
      "Epoch 321/1000\n",
      "74/74 - 0s - loss: 1.1660 - val_loss: 3.3019\n",
      "Epoch 322/1000\n",
      "74/74 - 0s - loss: 1.1615 - val_loss: 3.3017\n",
      "Epoch 323/1000\n",
      "74/74 - 0s - loss: 1.1653 - val_loss: 3.2988\n",
      "Epoch 324/1000\n",
      "74/74 - 0s - loss: 1.1622 - val_loss: 3.2998\n",
      "Epoch 325/1000\n",
      "74/74 - 0s - loss: 1.1615 - val_loss: 3.2930\n",
      "Epoch 326/1000\n",
      "74/74 - 0s - loss: 1.1586 - val_loss: 3.3020\n",
      "Epoch 327/1000\n",
      "74/74 - 0s - loss: 1.1585 - val_loss: 3.2932\n",
      "Epoch 328/1000\n",
      "74/74 - 0s - loss: 1.1608 - val_loss: 3.3085\n",
      "\n",
      "Epoch 00328: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 329/1000\n",
      "74/74 - 0s - loss: 1.1526 - val_loss: 3.2958\n",
      "Epoch 330/1000\n",
      "74/74 - 0s - loss: 1.1438 - val_loss: 3.2955\n",
      "Epoch 331/1000\n",
      "74/74 - 0s - loss: 1.1422 - val_loss: 3.2939\n",
      "Epoch 332/1000\n",
      "74/74 - 0s - loss: 1.1426 - val_loss: 3.3003\n",
      "Epoch 333/1000\n",
      "74/74 - 0s - loss: 1.1449 - val_loss: 3.2969\n",
      "Epoch 334/1000\n",
      "74/74 - 0s - loss: 1.1413 - val_loss: 3.2971\n",
      "Epoch 335/1000\n",
      "74/74 - 0s - loss: 1.1419 - val_loss: 3.2921\n",
      "Epoch 336/1000\n",
      "74/74 - 0s - loss: 1.1414 - val_loss: 3.2979\n",
      "Epoch 337/1000\n",
      "74/74 - 0s - loss: 1.1401 - val_loss: 3.2955\n",
      "Epoch 338/1000\n",
      "74/74 - 0s - loss: 1.1428 - val_loss: 3.2927\n",
      "Epoch 339/1000\n",
      "74/74 - 0s - loss: 1.1399 - val_loss: 3.3014\n",
      "Epoch 340/1000\n",
      "74/74 - 0s - loss: 1.1412 - val_loss: 3.2996\n",
      "Epoch 341/1000\n",
      "74/74 - 0s - loss: 1.1420 - val_loss: 3.2965\n",
      "Epoch 342/1000\n",
      "74/74 - 0s - loss: 1.1413 - val_loss: 3.2929\n",
      "Epoch 343/1000\n",
      "74/74 - 0s - loss: 1.1422 - val_loss: 3.2984\n",
      "Epoch 344/1000\n",
      "74/74 - 0s - loss: 1.1409 - val_loss: 3.2977\n",
      "Epoch 345/1000\n",
      "74/74 - 0s - loss: 1.1390 - val_loss: 3.2937\n",
      "Epoch 346/1000\n",
      "74/74 - 0s - loss: 1.1399 - val_loss: 3.2935\n",
      "Epoch 347/1000\n",
      "74/74 - 0s - loss: 1.1418 - val_loss: 3.2993\n",
      "Epoch 348/1000\n",
      "74/74 - 0s - loss: 1.1444 - val_loss: 3.3038\n",
      "Epoch 349/1000\n",
      "74/74 - 0s - loss: 1.1399 - val_loss: 3.2978\n",
      "Epoch 350/1000\n",
      "74/74 - 0s - loss: 1.1393 - val_loss: 3.2941\n",
      "Epoch 351/1000\n",
      "74/74 - 0s - loss: 1.1378 - val_loss: 3.2977\n",
      "Epoch 352/1000\n",
      "74/74 - 0s - loss: 1.1390 - val_loss: 3.2982\n",
      "Epoch 353/1000\n",
      "74/74 - 0s - loss: 1.1390 - val_loss: 3.2978\n",
      "Epoch 354/1000\n",
      "74/74 - 0s - loss: 1.1390 - val_loss: 3.2992\n",
      "Epoch 355/1000\n",
      "74/74 - 0s - loss: 1.1383 - val_loss: 3.2948\n",
      "Epoch 356/1000\n",
      "74/74 - 0s - loss: 1.1385 - val_loss: 3.2961\n",
      "Epoch 357/1000\n",
      "74/74 - 0s - loss: 1.1389 - val_loss: 3.3099\n",
      "Epoch 358/1000\n",
      "74/74 - 0s - loss: 1.1399 - val_loss: 3.3027\n",
      "Epoch 359/1000\n",
      "74/74 - 0s - loss: 1.1388 - val_loss: 3.3023\n",
      "Epoch 360/1000\n",
      "74/74 - 0s - loss: 1.1377 - val_loss: 3.2943\n",
      "Epoch 361/1000\n",
      "74/74 - 0s - loss: 1.1377 - val_loss: 3.2946\n",
      "Epoch 362/1000\n",
      "74/74 - 0s - loss: 1.1377 - val_loss: 3.2960\n",
      "Epoch 363/1000\n",
      "74/74 - 0s - loss: 1.1392 - val_loss: 3.3012\n",
      "Epoch 364/1000\n",
      "74/74 - 0s - loss: 1.1372 - val_loss: 3.2959\n",
      "Epoch 365/1000\n",
      "74/74 - 0s - loss: 1.1351 - val_loss: 3.3008\n",
      "Epoch 366/1000\n",
      "74/74 - 0s - loss: 1.1352 - val_loss: 3.2955\n",
      "Epoch 367/1000\n",
      "74/74 - 0s - loss: 1.1352 - val_loss: 3.3024\n",
      "Epoch 368/1000\n",
      "74/74 - 0s - loss: 1.1363 - val_loss: 3.2957\n",
      "Epoch 369/1000\n",
      "74/74 - 0s - loss: 1.1343 - val_loss: 3.2976\n",
      "Epoch 370/1000\n",
      "74/74 - 0s - loss: 1.1357 - val_loss: 3.3004\n",
      "Epoch 371/1000\n",
      "74/74 - 0s - loss: 1.1343 - val_loss: 3.2971\n",
      "Epoch 372/1000\n",
      "74/74 - 0s - loss: 1.1356 - val_loss: 3.2972\n",
      "Epoch 373/1000\n",
      "74/74 - 0s - loss: 1.1361 - val_loss: 3.3000\n",
      "Epoch 374/1000\n",
      "74/74 - 0s - loss: 1.1333 - val_loss: 3.3003\n",
      "Epoch 375/1000\n",
      "74/74 - 0s - loss: 1.1358 - val_loss: 3.3008\n",
      "Epoch 376/1000\n",
      "74/74 - 0s - loss: 1.1359 - val_loss: 3.2949\n",
      "Epoch 377/1000\n",
      "74/74 - 0s - loss: 1.1343 - val_loss: 3.3039\n",
      "Epoch 378/1000\n",
      "74/74 - 0s - loss: 1.1340 - val_loss: 3.3037\n",
      "Epoch 379/1000\n",
      "74/74 - 0s - loss: 1.1341 - val_loss: 3.2998\n",
      "Epoch 380/1000\n",
      "74/74 - 0s - loss: 1.1324 - val_loss: 3.2971\n",
      "Epoch 381/1000\n",
      "74/74 - 0s - loss: 1.1336 - val_loss: 3.2976\n",
      "Epoch 382/1000\n",
      "74/74 - 0s - loss: 1.1317 - val_loss: 3.2980\n",
      "Epoch 383/1000\n",
      "74/74 - 0s - loss: 1.1332 - val_loss: 3.3005\n",
      "Epoch 384/1000\n",
      "74/74 - 0s - loss: 1.1322 - val_loss: 3.2983\n",
      "Epoch 385/1000\n",
      "74/74 - 0s - loss: 1.1330 - val_loss: 3.3005\n",
      "Epoch 386/1000\n",
      "74/74 - 0s - loss: 1.1305 - val_loss: 3.2981\n",
      "Epoch 387/1000\n",
      "74/74 - 0s - loss: 1.1313 - val_loss: 3.2966\n",
      "Epoch 388/1000\n",
      "74/74 - 0s - loss: 1.1326 - val_loss: 3.3006\n",
      "Epoch 389/1000\n",
      "74/74 - 0s - loss: 1.1335 - val_loss: 3.3005\n",
      "Epoch 390/1000\n",
      "74/74 - 0s - loss: 1.1318 - val_loss: 3.3027\n",
      "Epoch 391/1000\n",
      "74/74 - 0s - loss: 1.1308 - val_loss: 3.2995\n",
      "Epoch 392/1000\n",
      "74/74 - 0s - loss: 1.1298 - val_loss: 3.3016\n",
      "Epoch 393/1000\n",
      "74/74 - 0s - loss: 1.1292 - val_loss: 3.2940\n",
      "Epoch 394/1000\n",
      "74/74 - 0s - loss: 1.1292 - val_loss: 3.3031\n",
      "Epoch 395/1000\n",
      "74/74 - 0s - loss: 1.1301 - val_loss: 3.3010\n",
      "Epoch 396/1000\n",
      "74/74 - 0s - loss: 1.1306 - val_loss: 3.3040\n",
      "Epoch 397/1000\n",
      "74/74 - 0s - loss: 1.1292 - val_loss: 3.3021\n",
      "Epoch 398/1000\n",
      "74/74 - 0s - loss: 1.1316 - val_loss: 3.3029\n",
      "Epoch 399/1000\n",
      "74/74 - 0s - loss: 1.1306 - val_loss: 3.3033\n",
      "Epoch 400/1000\n",
      "74/74 - 0s - loss: 1.1309 - val_loss: 3.3045\n",
      "Epoch 401/1000\n",
      "74/74 - 0s - loss: 1.1292 - val_loss: 3.2983\n",
      "Epoch 402/1000\n",
      "74/74 - 0s - loss: 1.1277 - val_loss: 3.2994\n",
      "Epoch 403/1000\n",
      "74/74 - 0s - loss: 1.1286 - val_loss: 3.3034\n",
      "Epoch 404/1000\n",
      "74/74 - 0s - loss: 1.1297 - val_loss: 3.2990\n",
      "Epoch 405/1000\n",
      "74/74 - 0s - loss: 1.1302 - val_loss: 3.3049\n",
      "Epoch 406/1000\n",
      "74/74 - 0s - loss: 1.1278 - val_loss: 3.3011\n",
      "Epoch 407/1000\n",
      "74/74 - 0s - loss: 1.1299 - val_loss: 3.3003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 408/1000\n",
      "74/74 - 0s - loss: 1.1275 - val_loss: 3.3003\n",
      "Epoch 409/1000\n",
      "74/74 - 0s - loss: 1.1292 - val_loss: 3.2997\n",
      "Epoch 410/1000\n",
      "74/74 - 0s - loss: 1.1286 - val_loss: 3.3055\n",
      "Epoch 411/1000\n",
      "74/74 - 0s - loss: 1.1278 - val_loss: 3.3002\n",
      "Epoch 412/1000\n",
      "74/74 - 0s - loss: 1.1292 - val_loss: 3.3024\n",
      "Epoch 413/1000\n",
      "74/74 - 0s - loss: 1.1269 - val_loss: 3.3007\n",
      "Epoch 414/1000\n",
      "74/74 - 0s - loss: 1.1276 - val_loss: 3.2991\n",
      "Epoch 415/1000\n",
      "74/74 - 0s - loss: 1.1271 - val_loss: 3.3009\n",
      "Epoch 416/1000\n",
      "74/74 - 0s - loss: 1.1274 - val_loss: 3.3014\n",
      "Epoch 417/1000\n",
      "74/74 - 0s - loss: 1.1293 - val_loss: 3.3043\n",
      "Epoch 418/1000\n",
      "74/74 - 0s - loss: 1.1276 - val_loss: 3.3025\n",
      "Epoch 419/1000\n",
      "74/74 - 0s - loss: 1.1251 - val_loss: 3.3028\n",
      "Epoch 420/1000\n",
      "74/74 - 0s - loss: 1.1259 - val_loss: 3.3035\n",
      "Epoch 421/1000\n",
      "74/74 - 0s - loss: 1.1282 - val_loss: 3.3096\n",
      "Epoch 422/1000\n",
      "74/74 - 0s - loss: 1.1273 - val_loss: 3.3068\n",
      "Epoch 423/1000\n",
      "74/74 - 0s - loss: 1.1237 - val_loss: 3.3012\n",
      "Epoch 424/1000\n",
      "74/74 - 0s - loss: 1.1249 - val_loss: 3.3044\n",
      "Epoch 425/1000\n",
      "74/74 - 0s - loss: 1.1256 - val_loss: 3.3035\n",
      "Epoch 426/1000\n",
      "74/74 - 0s - loss: 1.1245 - val_loss: 3.3034\n",
      "Epoch 427/1000\n",
      "74/74 - 0s - loss: 1.1236 - val_loss: 3.3027\n",
      "Epoch 428/1000\n",
      "74/74 - 0s - loss: 1.1250 - val_loss: 3.2980\n",
      "Epoch 429/1000\n",
      "74/74 - 0s - loss: 1.1255 - val_loss: 3.3037\n",
      "Epoch 430/1000\n",
      "74/74 - 0s - loss: 1.1236 - val_loss: 3.3025\n",
      "Epoch 431/1000\n",
      "74/74 - 0s - loss: 1.1228 - val_loss: 3.3045\n",
      "Epoch 432/1000\n",
      "74/74 - 0s - loss: 1.1224 - val_loss: 3.3018\n",
      "Epoch 433/1000\n",
      "74/74 - 0s - loss: 1.1251 - val_loss: 3.3053\n",
      "Epoch 434/1000\n",
      "74/74 - 0s - loss: 1.1232 - val_loss: 3.3035\n",
      "Epoch 435/1000\n",
      "74/74 - 0s - loss: 1.1251 - val_loss: 3.3020\n",
      "Epoch 436/1000\n",
      "74/74 - 0s - loss: 1.1229 - val_loss: 3.3052\n",
      "Epoch 437/1000\n",
      "74/74 - 0s - loss: 1.1231 - val_loss: 3.3031\n",
      "Epoch 438/1000\n",
      "74/74 - 0s - loss: 1.1227 - val_loss: 3.3020\n",
      "Epoch 439/1000\n",
      "74/74 - 0s - loss: 1.1248 - val_loss: 3.3003\n",
      "Epoch 440/1000\n",
      "74/74 - 0s - loss: 1.1214 - val_loss: 3.3075\n",
      "Epoch 441/1000\n",
      "74/74 - 0s - loss: 1.1224 - val_loss: 3.3022\n",
      "Epoch 442/1000\n",
      "74/74 - 0s - loss: 1.1229 - val_loss: 3.3096\n",
      "Epoch 443/1000\n",
      "74/74 - 0s - loss: 1.1226 - val_loss: 3.3074\n",
      "Epoch 444/1000\n",
      "74/74 - 0s - loss: 1.1207 - val_loss: 3.3079\n",
      "Epoch 445/1000\n",
      "74/74 - 0s - loss: 1.1216 - val_loss: 3.3030\n",
      "Epoch 446/1000\n",
      "74/74 - 0s - loss: 1.1227 - val_loss: 3.3094\n",
      "Epoch 447/1000\n",
      "74/74 - 0s - loss: 1.1247 - val_loss: 3.3054\n",
      "Epoch 448/1000\n",
      "74/74 - 0s - loss: 1.1201 - val_loss: 3.3065\n",
      "Epoch 449/1000\n",
      "74/74 - 0s - loss: 1.1226 - val_loss: 3.3046\n",
      "Epoch 450/1000\n",
      "74/74 - 0s - loss: 1.1197 - val_loss: 3.3064\n",
      "Epoch 451/1000\n",
      "74/74 - 0s - loss: 1.1205 - val_loss: 3.3072\n",
      "Epoch 452/1000\n",
      "74/74 - 0s - loss: 1.1202 - val_loss: 3.3063\n",
      "Epoch 453/1000\n",
      "74/74 - 0s - loss: 1.1244 - val_loss: 3.3044\n",
      "Epoch 454/1000\n",
      "74/74 - 0s - loss: 1.1210 - val_loss: 3.3037\n",
      "Epoch 455/1000\n",
      "74/74 - 0s - loss: 1.1188 - val_loss: 3.3028\n",
      "Epoch 456/1000\n",
      "74/74 - 0s - loss: 1.1194 - val_loss: 3.3045\n",
      "Epoch 457/1000\n",
      "74/74 - 0s - loss: 1.1184 - val_loss: 3.3086\n",
      "Epoch 458/1000\n",
      "74/74 - 0s - loss: 1.1194 - val_loss: 3.3042\n",
      "Epoch 459/1000\n",
      "74/74 - 0s - loss: 1.1184 - val_loss: 3.3002\n",
      "Epoch 460/1000\n",
      "74/74 - 0s - loss: 1.1199 - val_loss: 3.3039\n",
      "Epoch 461/1000\n",
      "74/74 - 0s - loss: 1.1191 - val_loss: 3.3054\n",
      "Epoch 462/1000\n",
      "74/74 - 0s - loss: 1.1171 - val_loss: 3.3050\n",
      "Epoch 463/1000\n",
      "74/74 - 0s - loss: 1.1189 - val_loss: 3.3025\n",
      "Epoch 464/1000\n",
      "74/74 - 0s - loss: 1.1207 - val_loss: 3.3078\n",
      "Epoch 465/1000\n",
      "74/74 - 0s - loss: 1.1197 - val_loss: 3.3114\n",
      "Epoch 466/1000\n",
      "74/74 - 0s - loss: 1.1185 - val_loss: 3.3116\n",
      "Epoch 467/1000\n",
      "74/74 - 0s - loss: 1.1221 - val_loss: 3.3060\n",
      "Epoch 468/1000\n",
      "74/74 - 0s - loss: 1.1170 - val_loss: 3.3008\n",
      "Epoch 469/1000\n",
      "74/74 - 0s - loss: 1.1175 - val_loss: 3.3074\n",
      "Epoch 470/1000\n",
      "74/74 - 0s - loss: 1.1206 - val_loss: 3.3054\n",
      "Epoch 471/1000\n",
      "74/74 - 0s - loss: 1.1171 - val_loss: 3.3030\n",
      "Epoch 472/1000\n",
      "74/74 - 0s - loss: 1.1168 - val_loss: 3.3033\n",
      "Epoch 473/1000\n",
      "74/74 - 0s - loss: 1.1160 - val_loss: 3.3031\n",
      "Epoch 474/1000\n",
      "74/74 - 0s - loss: 1.1147 - val_loss: 3.3143\n",
      "Epoch 475/1000\n",
      "74/74 - 0s - loss: 1.1193 - val_loss: 3.3089\n",
      "Epoch 476/1000\n",
      "74/74 - 0s - loss: 1.1159 - val_loss: 3.3051\n",
      "Epoch 477/1000\n",
      "74/74 - 0s - loss: 1.1170 - val_loss: 3.3075\n",
      "Epoch 478/1000\n",
      "74/74 - 0s - loss: 1.1153 - val_loss: 3.3100\n",
      "Epoch 479/1000\n",
      "74/74 - 0s - loss: 1.1159 - val_loss: 3.3070\n",
      "Epoch 480/1000\n",
      "74/74 - 0s - loss: 1.1174 - val_loss: 3.3039\n",
      "Epoch 481/1000\n",
      "74/74 - 0s - loss: 1.1169 - val_loss: 3.3021\n",
      "Epoch 482/1000\n",
      "74/74 - 0s - loss: 1.1165 - val_loss: 3.3045\n",
      "Epoch 483/1000\n",
      "74/74 - 0s - loss: 1.1161 - val_loss: 3.3121\n",
      "Epoch 484/1000\n",
      "74/74 - 0s - loss: 1.1153 - val_loss: 3.3094\n",
      "\n",
      "Epoch 00484: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 485/1000\n",
      "74/74 - 0s - loss: 1.1103 - val_loss: 3.3070\n",
      "Epoch 486/1000\n",
      "74/74 - 0s - loss: 1.1077 - val_loss: 3.3072\n",
      "Epoch 487/1000\n",
      "74/74 - 0s - loss: 1.1070 - val_loss: 3.3036\n",
      "Epoch 488/1000\n",
      "74/74 - 0s - loss: 1.1066 - val_loss: 3.3035\n",
      "Epoch 489/1000\n",
      "74/74 - 0s - loss: 1.1061 - val_loss: 3.3074\n",
      "Epoch 490/1000\n",
      "74/74 - 0s - loss: 1.1055 - val_loss: 3.3043\n",
      "Epoch 491/1000\n",
      "74/74 - 0s - loss: 1.1063 - val_loss: 3.3052\n",
      "Epoch 492/1000\n",
      "74/74 - 0s - loss: 1.1055 - val_loss: 3.3056\n",
      "Epoch 493/1000\n",
      "74/74 - 0s - loss: 1.1054 - val_loss: 3.3067\n",
      "Epoch 494/1000\n",
      "74/74 - 0s - loss: 1.1054 - val_loss: 3.3041\n",
      "Epoch 495/1000\n",
      "74/74 - 0s - loss: 1.1052 - val_loss: 3.3044\n",
      "Epoch 496/1000\n",
      "74/74 - 0s - loss: 1.1063 - val_loss: 3.3075\n",
      "Epoch 497/1000\n",
      "74/74 - 0s - loss: 1.1062 - val_loss: 3.3088\n",
      "Epoch 498/1000\n",
      "74/74 - 0s - loss: 1.1050 - val_loss: 3.3069\n",
      "Epoch 499/1000\n",
      "74/74 - 0s - loss: 1.1064 - val_loss: 3.3061\n",
      "Epoch 500/1000\n",
      "74/74 - 0s - loss: 1.1054 - val_loss: 3.3049\n",
      "Epoch 501/1000\n",
      "74/74 - 0s - loss: 1.1051 - val_loss: 3.3058\n",
      "Epoch 502/1000\n",
      "74/74 - 0s - loss: 1.1051 - val_loss: 3.3060\n",
      "Epoch 503/1000\n",
      "74/74 - 0s - loss: 1.1047 - val_loss: 3.3070\n",
      "Epoch 504/1000\n",
      "74/74 - 0s - loss: 1.1046 - val_loss: 3.3059\n",
      "Epoch 505/1000\n",
      "74/74 - 0s - loss: 1.1048 - val_loss: 3.3085\n",
      "Epoch 506/1000\n",
      "74/74 - 0s - loss: 1.1046 - val_loss: 3.3053\n",
      "Epoch 507/1000\n",
      "74/74 - 0s - loss: 1.1054 - val_loss: 3.3073\n",
      "Epoch 508/1000\n",
      "74/74 - 0s - loss: 1.1053 - val_loss: 3.3064\n",
      "Epoch 509/1000\n",
      "74/74 - 0s - loss: 1.1053 - val_loss: 3.3067\n",
      "Epoch 510/1000\n",
      "74/74 - 0s - loss: 1.1048 - val_loss: 3.3045\n",
      "Epoch 511/1000\n",
      "74/74 - 0s - loss: 1.1046 - val_loss: 3.3070\n",
      "Epoch 512/1000\n",
      "74/74 - 0s - loss: 1.1042 - val_loss: 3.3049\n",
      "Epoch 513/1000\n",
      "74/74 - 0s - loss: 1.1042 - val_loss: 3.3068\n",
      "Epoch 514/1000\n",
      "74/74 - 0s - loss: 1.1047 - val_loss: 3.3059\n",
      "Epoch 515/1000\n",
      "74/74 - 0s - loss: 1.1039 - val_loss: 3.3077\n",
      "Epoch 516/1000\n",
      "74/74 - 0s - loss: 1.1046 - val_loss: 3.3078\n",
      "Epoch 517/1000\n",
      "74/74 - 0s - loss: 1.1043 - val_loss: 3.3088\n",
      "Epoch 518/1000\n",
      "74/74 - 0s - loss: 1.1039 - val_loss: 3.3072\n",
      "Epoch 519/1000\n",
      "74/74 - 0s - loss: 1.1032 - val_loss: 3.3056\n",
      "Epoch 520/1000\n",
      "74/74 - 0s - loss: 1.1029 - val_loss: 3.3094\n",
      "Epoch 521/1000\n",
      "74/74 - 0s - loss: 1.1027 - val_loss: 3.3058\n",
      "Epoch 522/1000\n",
      "74/74 - 0s - loss: 1.1032 - val_loss: 3.3074\n",
      "Epoch 523/1000\n",
      "74/74 - 0s - loss: 1.1033 - val_loss: 3.3085\n",
      "Epoch 524/1000\n",
      "74/74 - 0s - loss: 1.1029 - val_loss: 3.3110\n",
      "Epoch 525/1000\n",
      "74/74 - 0s - loss: 1.1037 - val_loss: 3.3111\n",
      "Epoch 526/1000\n",
      "74/74 - 0s - loss: 1.1043 - val_loss: 3.3077\n",
      "Epoch 527/1000\n",
      "74/74 - 0s - loss: 1.1035 - val_loss: 3.3085\n",
      "Epoch 528/1000\n",
      "74/74 - 0s - loss: 1.1024 - val_loss: 3.3052\n",
      "Epoch 529/1000\n",
      "74/74 - 0s - loss: 1.1027 - val_loss: 3.3074\n",
      "Epoch 530/1000\n",
      "74/74 - 0s - loss: 1.1036 - val_loss: 3.3058\n",
      "Epoch 531/1000\n",
      "74/74 - 0s - loss: 1.1021 - val_loss: 3.3083\n",
      "Epoch 532/1000\n",
      "74/74 - 0s - loss: 1.1018 - val_loss: 3.3053\n",
      "Epoch 533/1000\n",
      "74/74 - 0s - loss: 1.1022 - val_loss: 3.3061\n",
      "Epoch 534/1000\n",
      "74/74 - 0s - loss: 1.1016 - val_loss: 3.3069\n",
      "Epoch 535/1000\n",
      "74/74 - 0s - loss: 1.1023 - val_loss: 3.3107\n",
      "Epoch 536/1000\n",
      "74/74 - 0s - loss: 1.1030 - val_loss: 3.3095\n",
      "Epoch 537/1000\n",
      "74/74 - 0s - loss: 1.1030 - val_loss: 3.3051\n",
      "Epoch 538/1000\n",
      "74/74 - 0s - loss: 1.1027 - val_loss: 3.3091\n",
      "Epoch 539/1000\n",
      "74/74 - 0s - loss: 1.1030 - val_loss: 3.3076\n",
      "Epoch 540/1000\n",
      "74/74 - 0s - loss: 1.1023 - val_loss: 3.3093\n",
      "Epoch 541/1000\n",
      "74/74 - 0s - loss: 1.1015 - val_loss: 3.3098\n",
      "Epoch 542/1000\n",
      "74/74 - 0s - loss: 1.1019 - val_loss: 3.3069\n",
      "Epoch 543/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 - 0s - loss: 1.1025 - val_loss: 3.3076\n",
      "Epoch 544/1000\n",
      "74/74 - 0s - loss: 1.1012 - val_loss: 3.3103\n",
      "Epoch 545/1000\n",
      "74/74 - 0s - loss: 1.1012 - val_loss: 3.3069\n",
      "Epoch 546/1000\n",
      "74/74 - 0s - loss: 1.1015 - val_loss: 3.3043\n",
      "Epoch 547/1000\n",
      "74/74 - 0s - loss: 1.1015 - val_loss: 3.3097\n",
      "Epoch 548/1000\n",
      "74/74 - 0s - loss: 1.1013 - val_loss: 3.3100\n",
      "Epoch 549/1000\n",
      "74/74 - 0s - loss: 1.1007 - val_loss: 3.3076\n",
      "Epoch 550/1000\n",
      "74/74 - 0s - loss: 1.1008 - val_loss: 3.3074\n",
      "Epoch 551/1000\n",
      "74/74 - 0s - loss: 1.1013 - val_loss: 3.3064\n",
      "Epoch 552/1000\n",
      "74/74 - 0s - loss: 1.1012 - val_loss: 3.3069\n",
      "Epoch 553/1000\n",
      "74/74 - 0s - loss: 1.1014 - val_loss: 3.3049\n",
      "Epoch 554/1000\n",
      "74/74 - 0s - loss: 1.1001 - val_loss: 3.3085\n",
      "Epoch 555/1000\n",
      "74/74 - 0s - loss: 1.0999 - val_loss: 3.3090\n",
      "Epoch 556/1000\n",
      "74/74 - 0s - loss: 1.1007 - val_loss: 3.3074\n",
      "Epoch 557/1000\n",
      "74/74 - 0s - loss: 1.1005 - val_loss: 3.3073\n",
      "Epoch 558/1000\n",
      "74/74 - 0s - loss: 1.1007 - val_loss: 3.3078\n",
      "Epoch 559/1000\n",
      "74/74 - 0s - loss: 1.1001 - val_loss: 3.3089\n",
      "Epoch 560/1000\n",
      "74/74 - 0s - loss: 1.1009 - val_loss: 3.3102\n",
      "Epoch 561/1000\n",
      "74/74 - 0s - loss: 1.1004 - val_loss: 3.3067\n",
      "Epoch 562/1000\n",
      "74/74 - 0s - loss: 1.0995 - val_loss: 3.3066\n",
      "Epoch 563/1000\n",
      "74/74 - 0s - loss: 1.0999 - val_loss: 3.3083\n",
      "Epoch 564/1000\n",
      "74/74 - 0s - loss: 1.1005 - val_loss: 3.3074\n",
      "Epoch 565/1000\n",
      "74/74 - 0s - loss: 1.0992 - val_loss: 3.3072\n",
      "Epoch 566/1000\n",
      "74/74 - 0s - loss: 1.0990 - val_loss: 3.3088\n",
      "Epoch 567/1000\n",
      "74/74 - 0s - loss: 1.0989 - val_loss: 3.3060\n",
      "Epoch 568/1000\n",
      "74/74 - 0s - loss: 1.0998 - val_loss: 3.3098\n",
      "Epoch 569/1000\n",
      "74/74 - 0s - loss: 1.0987 - val_loss: 3.3097\n",
      "Epoch 570/1000\n",
      "74/74 - 0s - loss: 1.0989 - val_loss: 3.3071\n",
      "Epoch 571/1000\n",
      "74/74 - 0s - loss: 1.0988 - val_loss: 3.3074\n",
      "Epoch 572/1000\n",
      "74/74 - 0s - loss: 1.0988 - val_loss: 3.3083\n",
      "Epoch 573/1000\n",
      "74/74 - 0s - loss: 1.0987 - val_loss: 3.3059\n",
      "Epoch 574/1000\n",
      "74/74 - 0s - loss: 1.0987 - val_loss: 3.3103\n",
      "Epoch 575/1000\n",
      "74/74 - 0s - loss: 1.0987 - val_loss: 3.3052\n",
      "Epoch 576/1000\n",
      "74/74 - 0s - loss: 1.0986 - val_loss: 3.3075\n",
      "Epoch 577/1000\n",
      "74/74 - 0s - loss: 1.0981 - val_loss: 3.3056\n",
      "Epoch 578/1000\n",
      "74/74 - 0s - loss: 1.0982 - val_loss: 3.3107\n",
      "Epoch 579/1000\n",
      "74/74 - 0s - loss: 1.0982 - val_loss: 3.3061\n",
      "Epoch 580/1000\n",
      "74/74 - 0s - loss: 1.0976 - val_loss: 3.3114\n",
      "Epoch 581/1000\n",
      "74/74 - 0s - loss: 1.0977 - val_loss: 3.3073\n",
      "Epoch 582/1000\n",
      "74/74 - 0s - loss: 1.0979 - val_loss: 3.3083\n",
      "Epoch 583/1000\n",
      "74/74 - 0s - loss: 1.0979 - val_loss: 3.3089\n",
      "Epoch 584/1000\n",
      "74/74 - 0s - loss: 1.0974 - val_loss: 3.3109\n",
      "Epoch 585/1000\n",
      "74/74 - 0s - loss: 1.0978 - val_loss: 3.3095\n",
      "Epoch 586/1000\n",
      "74/74 - 0s - loss: 1.0985 - val_loss: 3.3095\n",
      "Epoch 587/1000\n",
      "74/74 - 0s - loss: 1.0979 - val_loss: 3.3075\n",
      "Epoch 588/1000\n",
      "74/74 - 0s - loss: 1.0989 - val_loss: 3.3115\n",
      "Epoch 589/1000\n",
      "74/74 - 0s - loss: 1.0982 - val_loss: 3.3072\n",
      "Epoch 590/1000\n",
      "74/74 - 0s - loss: 1.0974 - val_loss: 3.3093\n",
      "Epoch 591/1000\n",
      "74/74 - 0s - loss: 1.0971 - val_loss: 3.3085\n",
      "Epoch 592/1000\n",
      "74/74 - 0s - loss: 1.0970 - val_loss: 3.3095\n",
      "Epoch 593/1000\n",
      "74/74 - 0s - loss: 1.0969 - val_loss: 3.3071\n",
      "Epoch 594/1000\n",
      "74/74 - 0s - loss: 1.0969 - val_loss: 3.3097\n",
      "Epoch 595/1000\n",
      "74/74 - 0s - loss: 1.0963 - val_loss: 3.3091\n",
      "Epoch 596/1000\n",
      "74/74 - 0s - loss: 1.0964 - val_loss: 3.3106\n",
      "Epoch 597/1000\n",
      "74/74 - 0s - loss: 1.0972 - val_loss: 3.3125\n",
      "Epoch 598/1000\n",
      "74/74 - 0s - loss: 1.0966 - val_loss: 3.3098\n",
      "Epoch 599/1000\n",
      "74/74 - 0s - loss: 1.0967 - val_loss: 3.3117\n",
      "Epoch 600/1000\n",
      "74/74 - 0s - loss: 1.0960 - val_loss: 3.3083\n",
      "Epoch 601/1000\n",
      "74/74 - 0s - loss: 1.0961 - val_loss: 3.3075\n",
      "Epoch 602/1000\n",
      "74/74 - 0s - loss: 1.0963 - val_loss: 3.3103\n",
      "Epoch 603/1000\n",
      "74/74 - 0s - loss: 1.0958 - val_loss: 3.3093\n",
      "Epoch 604/1000\n",
      "74/74 - 0s - loss: 1.0960 - val_loss: 3.3035\n",
      "Epoch 605/1000\n",
      "74/74 - 0s - loss: 1.0976 - val_loss: 3.3106\n",
      "Epoch 606/1000\n",
      "74/74 - 0s - loss: 1.0969 - val_loss: 3.3102\n",
      "Epoch 607/1000\n",
      "74/74 - 0s - loss: 1.0961 - val_loss: 3.3074\n",
      "Epoch 608/1000\n",
      "74/74 - 0s - loss: 1.0961 - val_loss: 3.3103\n",
      "Epoch 609/1000\n",
      "74/74 - 0s - loss: 1.0961 - val_loss: 3.3087\n",
      "Epoch 610/1000\n",
      "74/74 - 0s - loss: 1.0966 - val_loss: 3.3080\n",
      "Epoch 611/1000\n",
      "74/74 - 0s - loss: 1.0955 - val_loss: 3.3142\n",
      "Epoch 612/1000\n",
      "74/74 - 0s - loss: 1.0950 - val_loss: 3.3081\n",
      "Epoch 613/1000\n",
      "74/74 - 0s - loss: 1.0956 - val_loss: 3.3082\n",
      "Epoch 614/1000\n",
      "74/74 - 0s - loss: 1.0947 - val_loss: 3.3071\n",
      "Epoch 615/1000\n",
      "74/74 - 0s - loss: 1.0947 - val_loss: 3.3073\n",
      "Epoch 616/1000\n",
      "74/74 - 0s - loss: 1.0955 - val_loss: 3.3079\n",
      "Epoch 617/1000\n",
      "74/74 - 0s - loss: 1.0944 - val_loss: 3.3080\n",
      "Epoch 618/1000\n",
      "74/74 - 0s - loss: 1.0939 - val_loss: 3.3122\n",
      "Epoch 619/1000\n",
      "74/74 - 0s - loss: 1.0944 - val_loss: 3.3095\n",
      "Epoch 620/1000\n",
      "74/74 - 0s - loss: 1.0944 - val_loss: 3.3064\n",
      "Epoch 621/1000\n",
      "74/74 - 0s - loss: 1.0941 - val_loss: 3.3099\n",
      "Epoch 622/1000\n",
      "74/74 - 0s - loss: 1.0955 - val_loss: 3.3102\n",
      "Epoch 623/1000\n",
      "74/74 - 0s - loss: 1.0940 - val_loss: 3.3084\n",
      "Epoch 624/1000\n",
      "74/74 - 0s - loss: 1.0938 - val_loss: 3.3106\n",
      "Epoch 625/1000\n",
      "74/74 - 0s - loss: 1.0934 - val_loss: 3.3115\n",
      "Epoch 626/1000\n",
      "74/74 - 0s - loss: 1.0942 - val_loss: 3.3113\n",
      "Epoch 627/1000\n",
      "74/74 - 0s - loss: 1.0941 - val_loss: 3.3077\n",
      "Epoch 628/1000\n",
      "74/74 - 0s - loss: 1.0942 - val_loss: 3.3102\n",
      "Epoch 629/1000\n",
      "74/74 - 0s - loss: 1.0929 - val_loss: 3.3082\n",
      "Epoch 630/1000\n",
      "74/74 - 0s - loss: 1.0929 - val_loss: 3.3106\n",
      "Epoch 631/1000\n",
      "74/74 - 0s - loss: 1.0936 - val_loss: 3.3117\n",
      "Epoch 632/1000\n",
      "74/74 - 0s - loss: 1.0946 - val_loss: 3.3075\n",
      "Epoch 633/1000\n",
      "74/74 - 0s - loss: 1.0948 - val_loss: 3.3087\n",
      "Epoch 634/1000\n",
      "74/74 - 0s - loss: 1.0935 - val_loss: 3.3105\n",
      "Epoch 635/1000\n",
      "74/74 - 0s - loss: 1.0927 - val_loss: 3.3089\n",
      "Epoch 636/1000\n",
      "74/74 - 0s - loss: 1.0935 - val_loss: 3.3116\n",
      "Epoch 637/1000\n",
      "74/74 - 0s - loss: 1.0929 - val_loss: 3.3115\n",
      "Epoch 638/1000\n",
      "74/74 - 0s - loss: 1.0926 - val_loss: 3.3101\n",
      "Epoch 639/1000\n",
      "74/74 - 0s - loss: 1.0929 - val_loss: 3.3115\n",
      "Epoch 640/1000\n",
      "74/74 - 0s - loss: 1.0942 - val_loss: 3.3109\n",
      "Epoch 641/1000\n",
      "74/74 - 0s - loss: 1.0938 - val_loss: 3.3087\n",
      "Epoch 642/1000\n",
      "74/74 - 0s - loss: 1.0941 - val_loss: 3.3108\n",
      "Epoch 643/1000\n",
      "74/74 - 0s - loss: 1.0927 - val_loss: 3.3117\n",
      "Epoch 644/1000\n",
      "74/74 - 0s - loss: 1.0920 - val_loss: 3.3086\n",
      "Epoch 645/1000\n",
      "74/74 - 0s - loss: 1.0927 - val_loss: 3.3121\n",
      "Epoch 646/1000\n",
      "74/74 - 0s - loss: 1.0925 - val_loss: 3.3093\n",
      "Epoch 647/1000\n",
      "74/74 - 0s - loss: 1.0927 - val_loss: 3.3084\n",
      "Epoch 648/1000\n",
      "74/74 - 0s - loss: 1.0915 - val_loss: 3.3098\n",
      "Epoch 649/1000\n",
      "74/74 - 0s - loss: 1.0938 - val_loss: 3.3116\n",
      "Epoch 650/1000\n",
      "74/74 - 0s - loss: 1.0922 - val_loss: 3.3118\n",
      "Epoch 651/1000\n",
      "74/74 - 0s - loss: 1.0916 - val_loss: 3.3113\n",
      "Epoch 652/1000\n",
      "74/74 - 0s - loss: 1.0917 - val_loss: 3.3082\n",
      "Epoch 653/1000\n",
      "74/74 - 0s - loss: 1.0915 - val_loss: 3.3112\n",
      "Epoch 654/1000\n",
      "74/74 - 0s - loss: 1.0918 - val_loss: 3.3107\n",
      "Epoch 655/1000\n",
      "74/74 - 0s - loss: 1.0915 - val_loss: 3.3129\n",
      "Epoch 656/1000\n",
      "74/74 - 0s - loss: 1.0910 - val_loss: 3.3094\n",
      "Epoch 657/1000\n",
      "74/74 - 0s - loss: 1.0917 - val_loss: 3.3087\n",
      "Epoch 658/1000\n",
      "74/74 - 0s - loss: 1.0917 - val_loss: 3.3101\n",
      "Epoch 659/1000\n",
      "74/74 - 0s - loss: 1.0921 - val_loss: 3.3115\n",
      "Epoch 660/1000\n",
      "74/74 - 0s - loss: 1.0911 - val_loss: 3.3090\n",
      "Epoch 661/1000\n",
      "74/74 - 0s - loss: 1.0904 - val_loss: 3.3121\n",
      "Epoch 662/1000\n",
      "74/74 - 0s - loss: 1.0913 - val_loss: 3.3101\n",
      "Epoch 663/1000\n",
      "74/74 - 0s - loss: 1.0915 - val_loss: 3.3107\n",
      "Epoch 664/1000\n",
      "74/74 - 0s - loss: 1.0903 - val_loss: 3.3072\n",
      "Epoch 665/1000\n",
      "74/74 - 0s - loss: 1.0906 - val_loss: 3.3096\n",
      "Epoch 666/1000\n",
      "74/74 - 0s - loss: 1.0908 - val_loss: 3.3096\n",
      "Epoch 667/1000\n",
      "74/74 - 0s - loss: 1.0909 - val_loss: 3.3150\n",
      "Epoch 668/1000\n",
      "74/74 - 0s - loss: 1.0920 - val_loss: 3.3096\n",
      "Epoch 669/1000\n",
      "74/74 - 0s - loss: 1.0901 - val_loss: 3.3111\n",
      "Epoch 670/1000\n",
      "74/74 - 0s - loss: 1.0907 - val_loss: 3.3126\n",
      "Epoch 671/1000\n",
      "74/74 - 0s - loss: 1.0903 - val_loss: 3.3107\n",
      "Epoch 672/1000\n",
      "74/74 - 0s - loss: 1.0913 - val_loss: 3.3125\n",
      "Epoch 673/1000\n",
      "74/74 - 0s - loss: 1.0904 - val_loss: 3.3117\n",
      "Epoch 674/1000\n",
      "74/74 - 0s - loss: 1.0905 - val_loss: 3.3094\n",
      "Epoch 675/1000\n",
      "74/74 - 0s - loss: 1.0911 - val_loss: 3.3120\n",
      "Epoch 676/1000\n",
      "74/74 - 0s - loss: 1.0899 - val_loss: 3.3111\n",
      "Epoch 677/1000\n",
      "74/74 - 0s - loss: 1.0898 - val_loss: 3.3092\n",
      "Epoch 678/1000\n",
      "74/74 - 0s - loss: 1.0898 - val_loss: 3.3106\n",
      "Epoch 679/1000\n",
      "74/74 - 0s - loss: 1.0902 - val_loss: 3.3109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 680/1000\n",
      "74/74 - 0s - loss: 1.0911 - val_loss: 3.3105\n",
      "Epoch 681/1000\n",
      "74/74 - 0s - loss: 1.0905 - val_loss: 3.3114\n",
      "Epoch 682/1000\n",
      "74/74 - 0s - loss: 1.0896 - val_loss: 3.3127\n",
      "Epoch 683/1000\n",
      "74/74 - 0s - loss: 1.0895 - val_loss: 3.3105\n",
      "Epoch 684/1000\n",
      "74/74 - 0s - loss: 1.0889 - val_loss: 3.3129\n",
      "Epoch 685/1000\n",
      "74/74 - 0s - loss: 1.0893 - val_loss: 3.3127\n",
      "Epoch 686/1000\n",
      "74/74 - 0s - loss: 1.0890 - val_loss: 3.3110\n",
      "Epoch 687/1000\n",
      "74/74 - 0s - loss: 1.0891 - val_loss: 3.3092\n",
      "Epoch 688/1000\n",
      "74/74 - 0s - loss: 1.0887 - val_loss: 3.3128\n",
      "Epoch 689/1000\n",
      "74/74 - 0s - loss: 1.0898 - val_loss: 3.3127\n",
      "Epoch 690/1000\n",
      "74/74 - 0s - loss: 1.0894 - val_loss: 3.3119\n",
      "Epoch 691/1000\n",
      "74/74 - 0s - loss: 1.0903 - val_loss: 3.3106\n",
      "Epoch 692/1000\n",
      "74/74 - 0s - loss: 1.0886 - val_loss: 3.3130\n",
      "Epoch 693/1000\n",
      "74/74 - 0s - loss: 1.0892 - val_loss: 3.3112\n",
      "Epoch 694/1000\n",
      "74/74 - 0s - loss: 1.0892 - val_loss: 3.3096\n",
      "Epoch 695/1000\n",
      "74/74 - 0s - loss: 1.0888 - val_loss: 3.3137\n",
      "Epoch 696/1000\n",
      "74/74 - 0s - loss: 1.0896 - val_loss: 3.3125\n",
      "Epoch 697/1000\n",
      "74/74 - 0s - loss: 1.0885 - val_loss: 3.3100\n",
      "Epoch 698/1000\n",
      "74/74 - 0s - loss: 1.0889 - val_loss: 3.3119\n",
      "Epoch 699/1000\n",
      "74/74 - 0s - loss: 1.0878 - val_loss: 3.3124\n",
      "Epoch 700/1000\n",
      "74/74 - 0s - loss: 1.0878 - val_loss: 3.3107\n",
      "Epoch 701/1000\n",
      "74/74 - 0s - loss: 1.0877 - val_loss: 3.3124\n",
      "Epoch 702/1000\n",
      "74/74 - 0s - loss: 1.0876 - val_loss: 3.3127\n",
      "Epoch 703/1000\n",
      "74/74 - 0s - loss: 1.0878 - val_loss: 3.3085\n",
      "Epoch 704/1000\n",
      "74/74 - 0s - loss: 1.0875 - val_loss: 3.3126\n",
      "Epoch 705/1000\n",
      "74/74 - 0s - loss: 1.0869 - val_loss: 3.3157\n",
      "Epoch 706/1000\n",
      "74/74 - 0s - loss: 1.0875 - val_loss: 3.3138\n",
      "Epoch 707/1000\n",
      "74/74 - 0s - loss: 1.0876 - val_loss: 3.3116\n",
      "Epoch 708/1000\n",
      "74/74 - 0s - loss: 1.0884 - val_loss: 3.3114\n",
      "Epoch 709/1000\n",
      "74/74 - 0s - loss: 1.0873 - val_loss: 3.3120\n",
      "Epoch 710/1000\n",
      "74/74 - 0s - loss: 1.0893 - val_loss: 3.3123\n",
      "Epoch 711/1000\n",
      "74/74 - 0s - loss: 1.0873 - val_loss: 3.3140\n",
      "Epoch 712/1000\n",
      "74/74 - 0s - loss: 1.0881 - val_loss: 3.3110\n",
      "Epoch 713/1000\n",
      "74/74 - 0s - loss: 1.0878 - val_loss: 3.3112\n",
      "Epoch 714/1000\n",
      "74/74 - 0s - loss: 1.0871 - val_loss: 3.3103\n",
      "Epoch 715/1000\n",
      "74/74 - 0s - loss: 1.0878 - val_loss: 3.3112\n",
      "\n",
      "Epoch 00715: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 716/1000\n",
      "74/74 - 0s - loss: 1.0838 - val_loss: 3.3112\n",
      "Epoch 717/1000\n",
      "74/74 - 0s - loss: 1.0827 - val_loss: 3.3104\n",
      "Epoch 718/1000\n",
      "74/74 - 0s - loss: 1.0827 - val_loss: 3.3107\n",
      "Epoch 719/1000\n",
      "74/74 - 0s - loss: 1.0829 - val_loss: 3.3116\n",
      "Epoch 720/1000\n",
      "74/74 - 0s - loss: 1.0825 - val_loss: 3.3106\n",
      "Epoch 721/1000\n",
      "74/74 - 0s - loss: 1.0831 - val_loss: 3.3113\n",
      "Epoch 722/1000\n",
      "74/74 - 0s - loss: 1.0823 - val_loss: 3.3124\n",
      "Epoch 723/1000\n",
      "74/74 - 0s - loss: 1.0824 - val_loss: 3.3118\n",
      "Epoch 724/1000\n",
      "74/74 - 0s - loss: 1.0826 - val_loss: 3.3117\n",
      "Epoch 725/1000\n",
      "74/74 - 0s - loss: 1.0831 - val_loss: 3.3133\n",
      "Epoch 726/1000\n",
      "74/74 - 0s - loss: 1.0827 - val_loss: 3.3102\n",
      "Epoch 727/1000\n",
      "74/74 - 0s - loss: 1.0827 - val_loss: 3.3126\n",
      "Epoch 728/1000\n",
      "74/74 - 0s - loss: 1.0823 - val_loss: 3.3114\n",
      "Epoch 729/1000\n",
      "74/74 - 0s - loss: 1.0822 - val_loss: 3.3125\n",
      "Epoch 730/1000\n",
      "74/74 - 0s - loss: 1.0821 - val_loss: 3.3127\n",
      "Epoch 731/1000\n",
      "74/74 - 0s - loss: 1.0821 - val_loss: 3.3119\n",
      "Epoch 732/1000\n",
      "74/74 - 0s - loss: 1.0824 - val_loss: 3.3109\n",
      "Epoch 733/1000\n",
      "74/74 - 0s - loss: 1.0820 - val_loss: 3.3130\n",
      "Epoch 734/1000\n",
      "74/74 - 0s - loss: 1.0822 - val_loss: 3.3114\n",
      "Epoch 735/1000\n",
      "74/74 - 0s - loss: 1.0822 - val_loss: 3.3133\n",
      "Epoch 736/1000\n",
      "74/74 - 0s - loss: 1.0821 - val_loss: 3.3121\n",
      "Epoch 737/1000\n",
      "74/74 - 0s - loss: 1.0820 - val_loss: 3.3110\n",
      "Epoch 738/1000\n",
      "74/74 - 0s - loss: 1.0825 - val_loss: 3.3113\n",
      "Epoch 739/1000\n",
      "74/74 - 0s - loss: 1.0822 - val_loss: 3.3126\n",
      "Epoch 740/1000\n",
      "74/74 - 0s - loss: 1.0821 - val_loss: 3.3115\n",
      "\n",
      "Epoch 00740: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 741/1000\n",
      "74/74 - 0s - loss: 1.0804 - val_loss: 3.3120\n",
      "Epoch 742/1000\n",
      "74/74 - 0s - loss: 1.0802 - val_loss: 3.3119\n",
      "Epoch 743/1000\n",
      "74/74 - 0s - loss: 1.0801 - val_loss: 3.3116\n",
      "Epoch 744/1000\n",
      "74/74 - 0s - loss: 1.0799 - val_loss: 3.3114\n",
      "Epoch 745/1000\n",
      "74/74 - 0s - loss: 1.0800 - val_loss: 3.3118\n",
      "Epoch 746/1000\n",
      "74/74 - 0s - loss: 1.0798 - val_loss: 3.3123\n",
      "Epoch 747/1000\n",
      "74/74 - 0s - loss: 1.0799 - val_loss: 3.3125\n",
      "Epoch 748/1000\n",
      "74/74 - 0s - loss: 1.0799 - val_loss: 3.3118\n",
      "Epoch 749/1000\n",
      "74/74 - 0s - loss: 1.0800 - val_loss: 3.3118\n",
      "Epoch 750/1000\n",
      "74/74 - 0s - loss: 1.0800 - val_loss: 3.3110\n",
      "Epoch 751/1000\n",
      "74/74 - 0s - loss: 1.0798 - val_loss: 3.3116\n",
      "Epoch 752/1000\n",
      "74/74 - 0s - loss: 1.0798 - val_loss: 3.3128\n",
      "Epoch 753/1000\n",
      "74/74 - 0s - loss: 1.0798 - val_loss: 3.3125\n",
      "Epoch 754/1000\n",
      "74/74 - 0s - loss: 1.0799 - val_loss: 3.3115\n",
      "Epoch 755/1000\n",
      "74/74 - 0s - loss: 1.0796 - val_loss: 3.3101\n",
      "Epoch 756/1000\n",
      "74/74 - 0s - loss: 1.0797 - val_loss: 3.3115\n",
      "Epoch 757/1000\n",
      "74/74 - 0s - loss: 1.0798 - val_loss: 3.3115\n",
      "Epoch 758/1000\n",
      "74/74 - 0s - loss: 1.0797 - val_loss: 3.3118\n",
      "Epoch 759/1000\n",
      "74/74 - 0s - loss: 1.0798 - val_loss: 3.3106\n",
      "Epoch 760/1000\n",
      "74/74 - 0s - loss: 1.0797 - val_loss: 3.3115\n",
      "Epoch 761/1000\n",
      "74/74 - 0s - loss: 1.0796 - val_loss: 3.3112\n",
      "Epoch 762/1000\n",
      "74/74 - 0s - loss: 1.0796 - val_loss: 3.3106\n",
      "Epoch 763/1000\n",
      "74/74 - 0s - loss: 1.0796 - val_loss: 3.3106\n",
      "Epoch 764/1000\n",
      "74/74 - 0s - loss: 1.0796 - val_loss: 3.3120\n",
      "Epoch 765/1000\n",
      "74/74 - 0s - loss: 1.0795 - val_loss: 3.3106\n",
      "Epoch 766/1000\n",
      "74/74 - 0s - loss: 1.0796 - val_loss: 3.3117\n",
      "Epoch 767/1000\n",
      "74/74 - 0s - loss: 1.0795 - val_loss: 3.3113\n",
      "Epoch 768/1000\n",
      "74/74 - 0s - loss: 1.0794 - val_loss: 3.3121\n",
      "Epoch 769/1000\n",
      "74/74 - 0s - loss: 1.0794 - val_loss: 3.3116\n",
      "Epoch 770/1000\n",
      "74/74 - 0s - loss: 1.0796 - val_loss: 3.3125\n",
      "Epoch 771/1000\n",
      "74/74 - 0s - loss: 1.0798 - val_loss: 3.3116\n",
      "Epoch 772/1000\n",
      "74/74 - 0s - loss: 1.0796 - val_loss: 3.3116\n",
      "Epoch 773/1000\n",
      "74/74 - 0s - loss: 1.0795 - val_loss: 3.3115\n",
      "Epoch 774/1000\n",
      "74/74 - 0s - loss: 1.0791 - val_loss: 3.3120\n",
      "Epoch 775/1000\n",
      "74/74 - 0s - loss: 1.0792 - val_loss: 3.3118\n",
      "Epoch 776/1000\n",
      "74/74 - 0s - loss: 1.0794 - val_loss: 3.3117\n",
      "Epoch 777/1000\n",
      "74/74 - 0s - loss: 1.0791 - val_loss: 3.3109\n",
      "Epoch 778/1000\n",
      "74/74 - 0s - loss: 1.0795 - val_loss: 3.3115\n",
      "Epoch 779/1000\n",
      "74/74 - 0s - loss: 1.0790 - val_loss: 3.3110\n",
      "Epoch 780/1000\n",
      "74/74 - 0s - loss: 1.0791 - val_loss: 3.3124\n",
      "Epoch 781/1000\n",
      "74/74 - 0s - loss: 1.0790 - val_loss: 3.3125\n",
      "Epoch 782/1000\n",
      "74/74 - 0s - loss: 1.0791 - val_loss: 3.3118\n",
      "Epoch 783/1000\n",
      "74/74 - 0s - loss: 1.0792 - val_loss: 3.3114\n",
      "Epoch 784/1000\n",
      "74/74 - 0s - loss: 1.0789 - val_loss: 3.3116\n",
      "Epoch 785/1000\n",
      "74/74 - 0s - loss: 1.0792 - val_loss: 3.3119\n",
      "Epoch 786/1000\n",
      "74/74 - 0s - loss: 1.0790 - val_loss: 3.3126\n",
      "Epoch 787/1000\n",
      "74/74 - 0s - loss: 1.0788 - val_loss: 3.3103\n",
      "Epoch 788/1000\n",
      "74/74 - 0s - loss: 1.0791 - val_loss: 3.3112\n",
      "Epoch 789/1000\n",
      "74/74 - 0s - loss: 1.0791 - val_loss: 3.3118\n",
      "Epoch 790/1000\n",
      "74/74 - 0s - loss: 1.0791 - val_loss: 3.3113\n",
      "Epoch 791/1000\n",
      "74/74 - 0s - loss: 1.0788 - val_loss: 3.3122\n",
      "Epoch 792/1000\n",
      "74/74 - 0s - loss: 1.0788 - val_loss: 3.3109\n",
      "Epoch 793/1000\n",
      "74/74 - 0s - loss: 1.0788 - val_loss: 3.3121\n",
      "Epoch 794/1000\n",
      "74/74 - 0s - loss: 1.0788 - val_loss: 3.3117\n",
      "Epoch 795/1000\n",
      "74/74 - 0s - loss: 1.0788 - val_loss: 3.3113\n",
      "Epoch 796/1000\n",
      "74/74 - 0s - loss: 1.0787 - val_loss: 3.3119\n",
      "Epoch 797/1000\n",
      "74/74 - 0s - loss: 1.0789 - val_loss: 3.3107\n",
      "Epoch 798/1000\n",
      "74/74 - 0s - loss: 1.0787 - val_loss: 3.3114\n",
      "Epoch 799/1000\n",
      "74/74 - 0s - loss: 1.0788 - val_loss: 3.3125\n",
      "Epoch 800/1000\n",
      "74/74 - 0s - loss: 1.0786 - val_loss: 3.3123\n",
      "Epoch 801/1000\n",
      "74/74 - 0s - loss: 1.0786 - val_loss: 3.3114\n",
      "Epoch 802/1000\n",
      "74/74 - 0s - loss: 1.0787 - val_loss: 3.3119\n",
      "Epoch 803/1000\n",
      "74/74 - 0s - loss: 1.0786 - val_loss: 3.3119\n",
      "Epoch 804/1000\n",
      "74/74 - 0s - loss: 1.0786 - val_loss: 3.3115\n",
      "Epoch 805/1000\n",
      "74/74 - 0s - loss: 1.0789 - val_loss: 3.3110\n",
      "Epoch 806/1000\n",
      "74/74 - 0s - loss: 1.0785 - val_loss: 3.3112\n",
      "Epoch 807/1000\n",
      "74/74 - 0s - loss: 1.0785 - val_loss: 3.3121\n",
      "Epoch 808/1000\n",
      "74/74 - 0s - loss: 1.0784 - val_loss: 3.3108\n",
      "Epoch 809/1000\n",
      "74/74 - 0s - loss: 1.0785 - val_loss: 3.3117\n",
      "Epoch 810/1000\n",
      "74/74 - 0s - loss: 1.0783 - val_loss: 3.3125\n",
      "Epoch 811/1000\n",
      "74/74 - 0s - loss: 1.0784 - val_loss: 3.3107\n",
      "Epoch 812/1000\n",
      "74/74 - 0s - loss: 1.0786 - val_loss: 3.3117\n",
      "Epoch 813/1000\n",
      "74/74 - 0s - loss: 1.0785 - val_loss: 3.3111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 814/1000\n",
      "74/74 - 0s - loss: 1.0784 - val_loss: 3.3109\n",
      "Epoch 815/1000\n",
      "74/74 - 0s - loss: 1.0782 - val_loss: 3.3117\n",
      "Epoch 816/1000\n",
      "74/74 - 0s - loss: 1.0782 - val_loss: 3.3119\n",
      "Epoch 817/1000\n",
      "74/74 - 0s - loss: 1.0782 - val_loss: 3.3113\n",
      "Epoch 818/1000\n",
      "74/74 - 0s - loss: 1.0782 - val_loss: 3.3113\n",
      "Epoch 819/1000\n",
      "74/74 - 0s - loss: 1.0781 - val_loss: 3.3119\n",
      "Epoch 820/1000\n",
      "74/74 - 0s - loss: 1.0781 - val_loss: 3.3111\n",
      "Epoch 821/1000\n",
      "74/74 - 0s - loss: 1.0782 - val_loss: 3.3113\n",
      "Epoch 822/1000\n",
      "74/74 - 0s - loss: 1.0780 - val_loss: 3.3111\n",
      "Epoch 823/1000\n",
      "74/74 - 0s - loss: 1.0780 - val_loss: 3.3114\n",
      "Epoch 824/1000\n",
      "74/74 - 0s - loss: 1.0781 - val_loss: 3.3121\n",
      "Epoch 825/1000\n",
      "74/74 - 0s - loss: 1.0779 - val_loss: 3.3111\n",
      "Epoch 826/1000\n",
      "74/74 - 0s - loss: 1.0781 - val_loss: 3.3123\n",
      "Epoch 827/1000\n",
      "74/74 - 0s - loss: 1.0779 - val_loss: 3.3115\n",
      "Epoch 828/1000\n",
      "74/74 - 0s - loss: 1.0782 - val_loss: 3.3109\n",
      "Epoch 829/1000\n",
      "74/74 - 0s - loss: 1.0780 - val_loss: 3.3116\n",
      "Epoch 830/1000\n",
      "74/74 - 0s - loss: 1.0779 - val_loss: 3.3112\n",
      "Epoch 831/1000\n",
      "74/74 - 0s - loss: 1.0779 - val_loss: 3.3119\n",
      "Epoch 832/1000\n",
      "74/74 - 0s - loss: 1.0784 - val_loss: 3.3122\n",
      "\n",
      "Epoch 00832: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 833/1000\n",
      "74/74 - 0s - loss: 1.0774 - val_loss: 3.3115\n",
      "Epoch 834/1000\n",
      "74/74 - 0s - loss: 1.0770 - val_loss: 3.3115\n",
      "Epoch 835/1000\n",
      "74/74 - 0s - loss: 1.0769 - val_loss: 3.3109\n",
      "Epoch 836/1000\n",
      "74/74 - 0s - loss: 1.0769 - val_loss: 3.3115\n",
      "Epoch 837/1000\n",
      "74/74 - 0s - loss: 1.0768 - val_loss: 3.3112\n",
      "Epoch 838/1000\n",
      "74/74 - 0s - loss: 1.0768 - val_loss: 3.3117\n",
      "Epoch 839/1000\n",
      "74/74 - 0s - loss: 1.0768 - val_loss: 3.3113\n",
      "Epoch 840/1000\n",
      "74/74 - 0s - loss: 1.0768 - val_loss: 3.3118\n",
      "Epoch 841/1000\n",
      "74/74 - 0s - loss: 1.0768 - val_loss: 3.3116\n",
      "Epoch 842/1000\n",
      "74/74 - 0s - loss: 1.0767 - val_loss: 3.3115\n",
      "Epoch 843/1000\n",
      "74/74 - 0s - loss: 1.0769 - val_loss: 3.3118\n",
      "Epoch 844/1000\n",
      "74/74 - 0s - loss: 1.0768 - val_loss: 3.3114\n",
      "Epoch 845/1000\n",
      "74/74 - 0s - loss: 1.0768 - val_loss: 3.3112\n",
      "Epoch 846/1000\n",
      "74/74 - 0s - loss: 1.0767 - val_loss: 3.3112\n",
      "Epoch 847/1000\n",
      "74/74 - 0s - loss: 1.0769 - val_loss: 3.3109\n",
      "Epoch 848/1000\n",
      "74/74 - 0s - loss: 1.0768 - val_loss: 3.3112\n",
      "Epoch 849/1000\n",
      "74/74 - 0s - loss: 1.0768 - val_loss: 3.3116\n",
      "Epoch 850/1000\n",
      "74/74 - 0s - loss: 1.0767 - val_loss: 3.3113\n",
      "Epoch 851/1000\n",
      "74/74 - 0s - loss: 1.0767 - val_loss: 3.3113\n",
      "Epoch 852/1000\n",
      "74/74 - 0s - loss: 1.0767 - val_loss: 3.3117\n",
      "\n",
      "Epoch 00852: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Epoch 853/1000\n",
      "74/74 - 0s - loss: 1.0763 - val_loss: 3.3115\n",
      "Epoch 854/1000\n",
      "74/74 - 0s - loss: 1.0763 - val_loss: 3.3115\n",
      "Epoch 855/1000\n",
      "74/74 - 0s - loss: 1.0763 - val_loss: 3.3114\n",
      "Epoch 856/1000\n",
      "74/74 - 0s - loss: 1.0762 - val_loss: 3.3113\n",
      "Epoch 857/1000\n",
      "74/74 - 0s - loss: 1.0762 - val_loss: 3.3111\n",
      "Epoch 858/1000\n",
      "74/74 - 0s - loss: 1.0762 - val_loss: 3.3113\n",
      "Epoch 859/1000\n",
      "74/74 - 0s - loss: 1.0762 - val_loss: 3.3114\n",
      "Epoch 860/1000\n",
      "74/74 - 0s - loss: 1.0763 - val_loss: 3.3117\n",
      "Epoch 861/1000\n",
      "74/74 - 0s - loss: 1.0761 - val_loss: 3.3113\n",
      "Epoch 862/1000\n",
      "74/74 - 0s - loss: 1.0762 - val_loss: 3.3115\n",
      "Epoch 863/1000\n",
      "74/74 - 0s - loss: 1.0762 - val_loss: 3.3113\n",
      "Epoch 864/1000\n",
      "74/74 - 0s - loss: 1.0762 - val_loss: 3.3115\n",
      "Epoch 865/1000\n",
      "74/74 - 0s - loss: 1.0761 - val_loss: 3.3112\n",
      "Epoch 866/1000\n",
      "74/74 - 0s - loss: 1.0761 - val_loss: 3.3115\n",
      "\n",
      "Epoch 00866: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "Epoch 867/1000\n",
      "74/74 - 0s - loss: 1.0760 - val_loss: 3.3112\n",
      "Epoch 868/1000\n",
      "74/74 - 0s - loss: 1.0759 - val_loss: 3.3113\n",
      "Epoch 869/1000\n",
      "74/74 - 0s - loss: 1.0759 - val_loss: 3.3111\n",
      "Epoch 870/1000\n",
      "74/74 - 0s - loss: 1.0759 - val_loss: 3.3112\n",
      "Epoch 871/1000\n",
      "74/74 - 0s - loss: 1.0759 - val_loss: 3.3112\n",
      "Epoch 872/1000\n",
      "74/74 - 0s - loss: 1.0759 - val_loss: 3.3112\n",
      "Epoch 873/1000\n",
      "74/74 - 0s - loss: 1.0759 - val_loss: 3.3113\n",
      "Epoch 874/1000\n",
      "74/74 - 0s - loss: 1.0759 - val_loss: 3.3112\n",
      "Epoch 875/1000\n",
      "74/74 - 0s - loss: 1.0759 - val_loss: 3.3112\n",
      "Epoch 876/1000\n",
      "74/74 - 0s - loss: 1.0759 - val_loss: 3.3111\n",
      "Epoch 877/1000\n",
      "74/74 - 0s - loss: 1.0759 - val_loss: 3.3112\n",
      "Epoch 878/1000\n",
      "74/74 - 0s - loss: 1.0759 - val_loss: 3.3112\n",
      "Epoch 879/1000\n",
      "74/74 - 0s - loss: 1.0759 - val_loss: 3.3112\n",
      "Epoch 880/1000\n",
      "74/74 - 0s - loss: 1.0759 - val_loss: 3.3112\n",
      "Epoch 881/1000\n",
      "74/74 - 0s - loss: 1.0759 - val_loss: 3.3112\n",
      "Epoch 882/1000\n",
      "74/74 - 0s - loss: 1.0759 - val_loss: 3.3113\n",
      "Epoch 883/1000\n",
      "74/74 - 0s - loss: 1.0759 - val_loss: 3.3112\n",
      "Epoch 884/1000\n",
      "74/74 - 0s - loss: 1.0759 - val_loss: 3.3114\n",
      "Epoch 885/1000\n",
      "74/74 - 0s - loss: 1.0759 - val_loss: 3.3113\n",
      "Epoch 886/1000\n",
      "74/74 - 0s - loss: 1.0759 - val_loss: 3.3114\n",
      "Epoch 887/1000\n",
      "74/74 - 0s - loss: 1.0758 - val_loss: 3.3113\n",
      "Epoch 888/1000\n",
      "74/74 - 0s - loss: 1.0759 - val_loss: 3.3111\n",
      "Epoch 889/1000\n",
      "74/74 - 0s - loss: 1.0759 - val_loss: 3.3113\n",
      "Epoch 890/1000\n",
      "74/74 - 0s - loss: 1.0759 - val_loss: 3.3112\n",
      "Epoch 891/1000\n",
      "74/74 - 0s - loss: 1.0758 - val_loss: 3.3113\n",
      "Epoch 892/1000\n",
      "74/74 - 0s - loss: 1.0758 - val_loss: 3.3113\n",
      "Epoch 893/1000\n",
      "74/74 - 0s - loss: 1.0758 - val_loss: 3.3114\n",
      "Epoch 894/1000\n",
      "74/74 - 0s - loss: 1.0758 - val_loss: 3.3113\n",
      "Epoch 895/1000\n",
      "74/74 - 0s - loss: 1.0758 - val_loss: 3.3112\n",
      "Epoch 896/1000\n",
      "74/74 - 0s - loss: 1.0758 - val_loss: 3.3113\n",
      "Epoch 897/1000\n",
      "74/74 - 0s - loss: 1.0758 - val_loss: 3.3113\n",
      "Epoch 898/1000\n",
      "74/74 - 0s - loss: 1.0758 - val_loss: 3.3113\n",
      "Epoch 899/1000\n",
      "74/74 - 0s - loss: 1.0758 - val_loss: 3.3114\n",
      "Epoch 900/1000\n",
      "74/74 - 0s - loss: 1.0758 - val_loss: 3.3112\n",
      "Epoch 901/1000\n",
      "74/74 - 0s - loss: 1.0758 - val_loss: 3.3113\n",
      "Wall time: 7min 3s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226768598e0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.Input(shape=(fp_train.shape[1],), sparse=True),\n",
    "    tf.keras.layers.Dense(2048, activation='relu'),\n",
    "    tf.keras.layers.Dense(1024, activation='relu'),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(spec_train.shape[1]),\n",
    "    tf.keras.layers.Lambda(lambda x: tf.math.abs(x)),\n",
    "    tf.keras.layers.Lambda(lambda x: x / tf.reduce_sum(x, axis=-1)[:, None])\n",
    "])\n",
    "\n",
    "model.compile(loss=emd_loss, optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), metrics=[])\n",
    "model.fit(fp_train, spec_train.values, batch_size=32, epochs=1000, validation_data=(fp_test, spec_test.values), verbose=2, callbacks=[\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.5, patience=10, verbose=1, min_delta=1e-4, min_lr=1e-6),\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='loss', min_delta=1e-4, patience=20)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e871025c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8243942045961454"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 4\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 4), tight_layout=True)\n",
    "axes[0].bar(db_test[i]['spectrum'][:, 0], db_test[i]['spectrum'][:, 1], width=20)\n",
    "axes[0].set_title('original', {'family': 'Times New Roman', 'size': 20})\n",
    "axes[1].bar([i.mid for i in spec_train.columns], spec_test.loc[i], width=20)\n",
    "axes[1].set_title('binned', {'family': 'Times New Roman', 'size': 20})\n",
    "axes[2].bar([i.mid for i in spec_train.columns], model.predict(tf.sparse.slice(fp_test, [i, 0], [1, fp_test.shape[1]]))[0], width=20)\n",
    "axes[2].set_title('predicted', {'family': 'Times New Roman', 'size': 20})\n",
    "\n",
    "emd_loss(spec_test.loc[i], model.predict(tf.sparse.slice(fp_test, [i, 0], [1, fp_test.shape[1]]))[0]).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f8665e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
